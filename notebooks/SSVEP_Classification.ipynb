{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"},{"sourceId":12135096,"sourceType":"datasetVersion","datasetId":7642099},{"sourceId":12159009,"sourceType":"datasetVersion","datasetId":7657825}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Enhanced SSVEP Classification Pipeline - Complete Implementation\n\n## Imports and Environment Setup","metadata":{"_uuid":"263c890f-6b90-4918-8379-b5a521c6dd03","_cell_guid":"4c7479bd-0720-4c47-968b-d9c2d6489923","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Enhanced SSVEP Classification Pipeline \nimport os\nimport numpy as np\nimport pandas as pd\nfrom scipy.signal import butter, filtfilt, iirnotch, welch, hilbert\nfrom scipy.fft import fft, fftfreq\nfrom scipy.linalg import eigh, inv, sqrtm\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, callbacks, regularizers, backend as K\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List, Tuple, Dict, Optional\nimport pickle\nimport warnings\nimport math\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(\"âœ… All libraries loaded successfully!\")\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")","metadata":{"_uuid":"2cc4261f-73f1-4d6b-a130-23149148d595","_cell_guid":"f3a1cc18-afbb-40d4-b50f-1f784a448598","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:24.818791Z","iopub.execute_input":"2025-07-24T06:08:24.819021Z","iopub.status.idle":"2025-07-24T06:08:40.670709Z","shell.execute_reply.started":"2025-07-24T06:08:24.819002Z","shell.execute_reply":"2025-07-24T06:08:40.670037Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"2025-07-24 06:08:29.200650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753337309.393709      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753337309.467428      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"âœ… All libraries loaded successfully!\nTensorFlow version: 2.18.0\nNumPy version: 1.26.4\nPandas version: 2.2.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Advanced SSVEP Preprocessing Class","metadata":{"_uuid":"a66556b5-88ce-4e04-ad0e-1c8b4b0490bf","_cell_guid":"f416e266-dd9f-4a5e-9633-801db42a737c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class AdvancedSSVEPPreprocessor:\n    \"\"\"State-of-the-art preprocessing pipeline for SSVEP\"\"\"\n    def __init__(self, fs=250):\n        self.fs = fs\n        # Optimized channel selection for SSVEP\n        self.primary_channels = ['OZ', 'PO7', 'PO8']  # Occipital region\n        self.secondary_channels = ['PZ', 'CZ']  # Supporting channels\n        self.all_channels = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n        self.eeg_indices = list(range(1, 9))  # Assuming EEG channels are columns 1-8\n        \n        # SSVEP stimulation frequencies\n        self.target_frequencies = {\n            'Forward': 7.0,\n            'Backward': 8.0,\n            'Left': 10.0,\n            'Right': 13.0\n        }\n        \n        # Filter bank configuration (optimized for SSVEP)\n        self.filter_banks = [\n            (6, 14),    # Wide band covering all frequencies\n            (6.5, 7.5), # Narrow band for 7Hz\n            (7.5, 8.5), # Narrow band for 8Hz\n            (9.5, 10.5), # Narrow band for 10Hz\n            (12.5, 13.5), # Narrow band for 13Hz\n            (14, 21),    # Second harmonic band\n            (21, 28),    # Third harmonic band\n        ]\n        \n    def preprocess_trial(self, trial_data, trial_length_sec=5.0):\n        \"\"\"Enhanced preprocessing with spatial filtering\"\"\"\n        # Skip first and last 1 second (transition periods)\n        skip_samples = int(1.0 * self.fs)\n        target_samples = int(trial_length_sec * self.fs)\n        \n        # Extract EEG channels from trial data\n        if isinstance(trial_data, pd.DataFrame):\n            # If columns exist, use them; otherwise use indices\n            if all(ch in trial_data.columns for ch in self.all_channels):\n                eeg_data = trial_data[self.all_channels].values\n            else:\n                # Use numeric indices (columns 1-8 for EEG)\n                eeg_data = trial_data.iloc[:, self.eeg_indices].values\n        else:\n            # Assume numpy array with EEG in columns 1-8\n            eeg_data = trial_data[:, self.eeg_indices]\n        \n        # Trim transition periods\n        if len(eeg_data) > skip_samples * 2:\n            eeg_data = eeg_data[skip_samples:-skip_samples]\n        \n        # Ensure correct length\n        eeg_data = self._adjust_signal_length(eeg_data, target_samples)\n        \n        # Process each channel\n        processed_data = []\n        for ch_idx in range(eeg_data.shape[1]):\n            signal = eeg_data[:, ch_idx]\n            \n            # Apply preprocessing\n            signal = self._advanced_preprocess(signal)\n            processed_data.append(signal)\n        \n        processed_data = np.array(processed_data)\n        \n        # Apply spatial filtering - add bipolar derivation if we have enough channels\n        if processed_data.shape[0] >= 8:  # Ensure we have all channels\n            # Add OZ-PZ derivation (channels 6 and 4)\n            bipolar = processed_data[6] - processed_data[4]\n            processed_data = np.vstack([processed_data, bipolar[np.newaxis, :]])\n        \n        return processed_data\n    \n    def _advanced_preprocess(self, signal):\n        \"\"\"Advanced signal preprocessing\"\"\"\n        # Remove DC offset\n        signal = signal - np.mean(signal)\n        \n        # High-pass filter at 1Hz (preserve SSVEP frequencies)\n        signal = self._highpass_filter(signal, 1.0, order=4)\n        \n        # Notch filters at 50Hz and harmonics\n        for freq in [50, 100]:\n            if freq < self.fs/2:\n                signal = self._notch_filter(signal, freq, quality=30)\n        \n        # Low-pass filter at 40Hz (remove high-frequency noise)\n        signal = self._lowpass_filter(signal, 40, order=4)\n        \n        # Advanced artifact rejection\n        signal = self._advanced_artifact_rejection(signal)\n        \n        # Robust normalization\n        signal = self._robust_normalize(signal)\n        \n        return signal\n    \n    def _advanced_artifact_rejection(self, signal):\n        \"\"\"Advanced artifact rejection using multiple criteria\"\"\"\n        # Amplitude-based rejection\n        q1, q3 = np.percentile(signal, [25, 75])\n        iqr = q3 - q1\n        lower_bound = q1 - 2.5 * iqr\n        upper_bound = q3 + 2.5 * iqr\n        \n        # Gradient-based rejection (for sudden jumps)\n        gradient = np.gradient(signal)\n        grad_threshold = 5 * np.std(gradient)\n        \n        # Combined rejection\n        artifact_mask = (signal < lower_bound) | (signal > upper_bound) | (np.abs(gradient) > grad_threshold)\n        \n        # Interpolate artifacts\n        if np.any(artifact_mask):\n            good_indices = np.where(~artifact_mask)[0]\n            bad_indices = np.where(artifact_mask)[0]\n            if len(good_indices) > 10:\n                signal[bad_indices] = np.interp(bad_indices, good_indices, signal[good_indices])\n        \n        return signal\n    \n    def _robust_normalize(self, signal):\n        \"\"\"Robust normalization using median and MAD\"\"\"\n        median = np.median(signal)\n        mad = np.median(np.abs(signal - median))\n        if mad > 0:\n            signal = (signal - median) / (mad * 1.4826)\n        return np.clip(signal, -4, 4)\n    \n    def _adjust_signal_length(self, signal, target_length):\n        \"\"\"Adjust signal to target length\"\"\"\n        if len(signal) > target_length:\n            return signal[:target_length]\n        elif len(signal) < target_length:\n            return np.pad(signal, (0, target_length - len(signal)), 'edge')\n        return signal\n    \n    def _highpass_filter(self, signal, cutoff, order=4):\n        \"\"\"Butterworth highpass filter\"\"\"\n        nyq = 0.5 * self.fs\n        normal_cutoff = cutoff / nyq\n        b, a = butter(order, normal_cutoff, btype='high', analog=False)\n        return filtfilt(b, a, signal)\n    \n    def _lowpass_filter(self, signal, cutoff, order=4):\n        \"\"\"Butterworth lowpass filter\"\"\"\n        nyq = 0.5 * self.fs\n        normal_cutoff = cutoff / nyq\n        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n        return filtfilt(b, a, signal)\n    \n    def _notch_filter(self, signal, freq, quality=30):\n        \"\"\"Notch filter for line noise removal\"\"\"\n        b, a = iirnotch(freq, quality, self.fs)\n        return filtfilt(b, a, signal)\n    \n    def _bandpass_filter(self, signal, low, high, order=4):\n        \"\"\"Butterworth bandpass filter\"\"\"\n        nyq = 0.5 * self.fs\n        low = low / nyq\n        high = high / nyq\n        \n        # Handle edge cases\n        if low <= 0:\n            low = 0.001\n        if high >= 1:\n            high = 0.999\n            \n        b, a = butter(order, [low, high], btype='band')\n        return filtfilt(b, a, signal)\n\nprint(\"âœ… Advanced SSVEP Preprocessor class defined\")","metadata":{"_uuid":"38e82eee-fd50-494a-8c1e-019cf10098cc","_cell_guid":"217fa105-6c60-4586-bda0-1ec62096a32f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.671922Z","iopub.execute_input":"2025-07-24T06:08:40.672272Z","iopub.status.idle":"2025-07-24T06:08:40.689188Z","shell.execute_reply.started":"2025-07-24T06:08:40.672255Z","shell.execute_reply":"2025-07-24T06:08:40.688425Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"âœ… Advanced SSVEP Preprocessor class defined\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Enhanced Deep Learning Models with Attention","metadata":{"_uuid":"13130a6c-60d8-449d-9c20-0baac85455c6","_cell_guid":"32eace75-067f-4d87-b3a3-66aa06b827bc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def create_attention_block(inputs, num_heads=4):\n    \"\"\"Multi-head attention block for EEG - Corrected Version\"\"\"\n    shape = list(inputs.shape)\n    \n    if len(shape) == 4:\n        _, height, width, features = shape\n        if height == 1:  # EEGNet case after DepthwiseConv2D\n            time_steps = width\n            reshaped = layers.Reshape((time_steps, features))(inputs)\n        else:\n            time_steps = height\n            reshaped = layers.Reshape((time_steps, width * features))(inputs)\n    else:\n        reshaped = inputs\n        time_steps = shape[1]\n    \n    # Multi-head attention\n    attention = layers.MultiHeadAttention(\n        num_heads=num_heads,\n        key_dim=features // num_heads if features >= num_heads else features,\n        dropout=0.1\n    )(reshaped, reshaped)\n    \n    # Add & Norm\n    attention = layers.Add()([reshaped, attention])\n    attention = layers.LayerNormalization(epsilon=1e-6)(attention)\n    \n    # Reshape back\n    if len(shape) == 4:\n        if height == 1:\n            output = layers.Reshape((1, time_steps, features))(attention)\n        else:\n            output = layers.Reshape((time_steps, width, features))(attention)\n    else:\n        output = attention\n    \n    return output\n\ndef EEGNet_SSVEP_Enhanced(nb_classes, Chans=8, Samples=1250, \n                          dropoutRate=0.25, kernLength=64, F1=16, D=2, F2=32,\n                          use_attention=True):\n    \"\"\"Enhanced EEGNet with attention mechanism for SSVEP - FIXED VERSION\"\"\"\n    \n    input_layer = layers.Input(shape=(Chans, Samples, 1))\n    \n    # Block 1: Temporal + Spatial Filtering\n    block1 = layers.Conv2D(F1, (1, kernLength), padding='same',\n                          use_bias=False,\n                          kernel_regularizer=regularizers.l2(0.0005))(input_layer)\n    block1 = layers.BatchNormalization()(block1)\n    \n    # Depthwise convolution\n    block1 = layers.DepthwiseConv2D((Chans, 1), use_bias=False,\n                                   depth_multiplier=D,\n                                   depthwise_constraint=tf.keras.constraints.max_norm(1.))(block1)\n    block1 = layers.BatchNormalization()(block1)\n    block1 = layers.Activation('elu')(block1)\n    block1 = layers.AveragePooling2D((1, 4))(block1)\n    block1 = layers.Dropout(dropoutRate)(block1)\n    \n    # Add attention after first block\n    if use_attention:\n        block1 = create_attention_block(block1, num_heads=4)\n    \n    # Block 2: Separable Convolution\n    block2 = layers.SeparableConv2D(F2, (1, 16),\n                                   use_bias=False, padding='same',\n                                   depthwise_regularizer=regularizers.l2(0.0005))(block1)\n    block2 = layers.BatchNormalization()(block2)\n    block2 = layers.Activation('elu')(block2)\n    block2 = layers.AveragePooling2D((1, 8))(block2)\n    block2 = layers.Dropout(dropoutRate)(block2)\n    \n    # Block 3: Additional Feature Extraction\n    block3 = layers.SeparableConv2D(F2*2, (1, 8),\n                                   use_bias=False, padding='same')(block2)\n    block3 = layers.BatchNormalization()(block3)\n    block3 = layers.Activation('elu')(block3)\n    \n    # Global Average Pooling\n    gap = layers.GlobalAveragePooling2D()(block3)\n    \n    # Dense layers with regularization\n    dense = layers.Dense(nb_classes*16, activation='elu',\n                        kernel_regularizer=regularizers.l2(0.001))(gap)\n    dense = layers.Dropout(0.3)(dense)\n    \n    dense2 = layers.Dense(nb_classes*8, activation='elu',\n                         kernel_regularizer=regularizers.l2(0.001))(dense)\n    dense2 = layers.Dropout(0.3)(dense2)\n    \n    # Output layer\n    output = layers.Dense(nb_classes, activation='softmax',\n                         kernel_constraint=tf.keras.constraints.max_norm(0.25))(dense2)\n    \n    return models.Model(inputs=input_layer, outputs=output)\n\nprint(\"âœ… Enhanced EEGNet with attention mechanism defined\")","metadata":{"_uuid":"1c97b2da-bd90-4791-b6f8-4492db3eb8b1","_cell_guid":"f2fdafb6-a3a1-4ec7-96cb-5a9cbb1a052a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.689838Z","iopub.execute_input":"2025-07-24T06:08:40.690103Z","iopub.status.idle":"2025-07-24T06:08:40.718859Z","shell.execute_reply.started":"2025-07-24T06:08:40.690074Z","shell.execute_reply":"2025-07-24T06:08:40.718319Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"âœ… Enhanced EEGNet with attention mechanism defined\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Data Augmentation for SSVEP","metadata":{"_uuid":"449c200f-cd41-4854-8fe4-06bc9cf4b329","_cell_guid":"19fdc549-1e5a-4a9a-bb56-10a2d4eb8c7d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class SSVEPAugmentation:\n    \"\"\"Specialized augmentation techniques for SSVEP\"\"\"\n    def __init__(self, fs=250):\n        self.fs = fs\n        \n    def phase_perturbation(self, signal, max_shift_ms=50):\n        \"\"\"Apply phase perturbation to maintain frequency content\"\"\"\n        max_shift_samples = int(max_shift_ms * self.fs / 1000)\n        \n        augmented = []\n        for trial in signal:\n            # Random phase shift\n            shift = np.random.randint(-max_shift_samples, max_shift_samples)\n            \n            # Apply circular shift to each channel\n            shifted_trial = np.zeros_like(trial)\n            for ch in range(trial.shape[0]):\n                shifted_trial[ch] = np.roll(trial[ch], shift)\n            \n            augmented.append(shifted_trial)\n        \n        return np.array(augmented)\n    \n    def amplitude_perturbation(self, signal, scale_range=(0.8, 1.2)):\n        \"\"\"Scale amplitude while preserving relative relationships\"\"\"\n        augmented = []\n        \n        for trial in signal:\n            # Random scaling factor\n            scale = np.random.uniform(scale_range[0], scale_range[1])\n            augmented.append(trial * scale)\n        \n        return np.array(augmented)\n    \n    def frequency_masking(self, signal, preprocessor, mask_prob=0.1):\n        \"\"\"Mask specific frequency bands\"\"\"\n        augmented = []\n        \n        for trial in signal:\n            masked_trial = trial.copy()\n            \n            # Randomly mask frequency bands\n            for ch in range(trial.shape[0]):\n                if np.random.random() < mask_prob:\n                    # Apply random notch filter\n                    notch_freq = np.random.uniform(6, 20)\n                    masked_trial[ch] = preprocessor._notch_filter(\n                        masked_trial[ch], notch_freq, quality=5\n                    )\n            \n            augmented.append(masked_trial)\n        \n        return np.array(augmented)\n        \n    def random_phase_erasing(self, X, erase_ratio=0.1):\n        \"\"\"\n        Random Phase Erasing (RPE) - randomly erases phase information\n        \"\"\"\n        augmented = []\n        \n        for trial in X:\n            erased_trial = trial.copy()\n            n_channels, n_samples = trial.shape\n            \n            # Apply FFT\n            fft_trial = np.fft.fft(trial, axis=1)\n            magnitude = np.abs(fft_trial)\n            phase = np.angle(fft_trial)\n            \n            # Randomly erase phase information\n            for ch in range(n_channels):\n                erase_idx = np.random.choice(n_samples, \n                                           int(n_samples * erase_ratio), \n                                           replace=False)\n                # Set phase to random values\n                phase[ch, erase_idx] = np.random.uniform(-np.pi, np.pi, \n                                                         len(erase_idx))\n            \n            # Reconstruct signal\n            fft_reconstructed = magnitude * np.exp(1j * phase)\n            erased_trial = np.real(np.fft.ifft(fft_reconstructed, axis=1))\n            augmented.append(erased_trial)\n        \n        return np.array(augmented)\n\nprint(\"âœ… SSVEP Augmentation class defined\")","metadata":{"_uuid":"c79cc1dc-ddf6-4b26-aa50-fbf4cccffcf5","_cell_guid":"b043fee5-19ef-4da1-a0e7-c09cbaf74688","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.720327Z","iopub.execute_input":"2025-07-24T06:08:40.720718Z","iopub.status.idle":"2025-07-24T06:08:40.741675Z","shell.execute_reply.started":"2025-07-24T06:08:40.720702Z","shell.execute_reply":"2025-07-24T06:08:40.741055Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"âœ… SSVEP Augmentation class defined\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Custom Schedulers and Loss Functions","metadata":{"_uuid":"decccf68-6a35-47a5-978f-407aa42bfe5d","_cell_guid":"b2ef83a6-b814-419d-bd12-47522356c05d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Cosine-annealing with warm restarts  (SGDR, Loshchilov & Hutter '16)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nclass SGDRScheduler(tf.keras.callbacks.Callback):\n    \"\"\"\n    Cosine-annealing LR schedule with warm restarts (SGDR).\n\n    Parameters\n    ----------\n    T_0 : int   â€“ epochs in the first cosine cycle\n    T_mult : int â€“ cycle-length multiplier\n    eta_max : float â€“ peak LR at the start of each cycle\n    eta_min : float â€“ floor LR at the end of a cycle\n    verbose : int â€“ 0 = silent, 1 = line per epoch\n    \"\"\"\n    def __init__(self,\n                 T_0: int = 30,\n                 T_mult: int = 2,\n                 eta_max: float = 3e-4,\n                 eta_min: float = 1e-6,\n                 verbose: int = 1):\n        super().__init__()\n        self.T_0, self.T_mult = T_0, T_mult\n        self.eta_max, self.eta_min, self.verbose = eta_max, eta_min, verbose\n\n        # internal state\n        self.T_cur, self.T_i = 0, T_0           # epochs since restart, cycle length\n\n    # -------------------------------------------------- helpers\n    @staticmethod\n    def _is_tf_variable(x):\n        return isinstance(x, (tf.Variable, tf.Tensor)) and hasattr(x, \"assign\")\n\n    def _set_optimizer_lr(self, lr: float):\n        \"\"\"Safely write `lr` into whatever object the optimizer is using.\"\"\"\n        opt = self.model.optimizer\n        # modern attribute\n        if hasattr(opt, \"learning_rate\"):\n            if self._is_tf_variable(opt.learning_rate):\n                opt.learning_rate.assign(lr)\n            else:\n                opt.learning_rate = lr\n            return\n        # legacy attribute\n        if hasattr(opt, \"lr\"):\n            if self._is_tf_variable(opt.lr):\n                opt.lr.assign(lr)\n            else:\n                opt.lr = lr\n\n    # -------------------------------------------------- Keras hooks\n    def on_epoch_begin(self, epoch, logs=None):\n        if self.T_cur >= self.T_i:              # restart\n            self.T_cur = 0\n            self.T_i   = self.T_i * self.T_mult\n\n        # cosine decay\n        cos_inner = math.pi * self.T_cur / self.T_i\n        lr = self.eta_min + 0.5 * (self.eta_max - self.eta_min) * (1 + math.cos(cos_inner))\n\n        self._set_optimizer_lr(lr)              # <<â€“â€“ robust setter\n        self.T_cur += 1\n\n        if self.verbose:\n            print(f\"\\nEpoch {epoch+1:03d} â€” SGDR LR: {lr:.6g}\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Focal-loss with label-smoothing\n# ----------------------------------------------------------------------\n\ndef focal_loss_ls(gamma=2.0, alpha=0.75, label_smoothing=0.05, class_weights=None):\n    \"\"\"Focal loss with class weighting\"\"\"\n    def _loss(y_true, y_pred):\n        # Label smoothing\n        if label_smoothing > 0:\n            num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n            y_true = (1.0 - label_smoothing) * y_true + label_smoothing / num_classes\n        \n        # Apply class weights if provided\n        if class_weights is not None:\n            # Convert class weights to tensor\n            weights_tensor = tf.constant(list(class_weights.values()), dtype=tf.float32)\n            # Get the class index for each sample\n            class_indices = tf.argmax(y_true, axis=1)\n            # Get the corresponding weight\n            sample_weights = tf.gather(weights_tensor, class_indices)\n            sample_weights = tf.expand_dims(sample_weights, 1)\n        else:\n            sample_weights = 1.0\n        \n        # Focal loss calculation\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1.0 - K.epsilon())\n        cross_ent = -y_true * tf.math.log(y_pred)\n        focal_mod = alpha * tf.pow(1.0 - y_pred, gamma)\n        loss = focal_mod * cross_ent * sample_weights\n        \n        return tf.reduce_sum(loss, axis=-1)\n    \n    return _loss\n\n# Initialize scheduler\nsgdr_sched = SGDRScheduler(T_0=30, T_mult=2,\n                           eta_max=3e-4, eta_min=1e-6,\n                           verbose=1)\n\nprint(\"âœ… Custom schedulers and loss functions defined\")","metadata":{"_uuid":"6ed75dd4-cb22-48db-9bda-06bdad51442b","_cell_guid":"1aadb731-db65-4b21-bccc-268f35615673","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.742264Z","iopub.execute_input":"2025-07-24T06:08:40.742487Z","iopub.status.idle":"2025-07-24T06:08:40.761364Z","shell.execute_reply.started":"2025-07-24T06:08:40.742464Z","shell.execute_reply":"2025-07-24T06:08:40.760798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"âœ… Custom schedulers and loss functions defined\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Data Loading Function","metadata":{"_uuid":"46c3eaee-3b12-4dac-98f3-58043ee1c633","_cell_guid":"35bf266b-d740-498c-825a-8ffef2386e70","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def load_ssvep_data(root_dir=\"/kaggle/input/mtcaic3\", samples_per_trial=1750):\n    \"\"\"Load SSVEP data\"\"\"\n    def read_split(split_name):\n        csv_path = os.path.join(root_dir, f\"{split_name}.csv\")\n        df = pd.read_csv(csv_path)\n        df_ssvep = df[df[\"task\"] == \"SSVEP\"]\n        split_data = []\n        \n        print(f\"Loading {split_name} SSVEP data...\")\n        \n        for idx, row in df_ssvep.iterrows():\n            if idx % 100 == 0:\n                print(f\"  Processed {idx}/{len(df_ssvep)} trials\", end='\\r')\n                \n            subject = f\"{row['subject_id']}\"\n            session = str(row[\"trial_session\"])\n            trial_num = row[\"trial\"]\n            label = row[\"label\"] if \"label\" in row and not pd.isna(row[\"label\"]) else None\n            \n            eeg_path = os.path.join(root_dir, \"SSVEP\", split_name, subject, session, \"EEGdata.csv\")\n            if not os.path.exists(eeg_path):\n                continue\n                \n            eeg_df = pd.read_csv(eeg_path)\n            start_idx = (trial_num - 1) * samples_per_trial\n            end_idx = start_idx + samples_per_trial\n            trial_data = eeg_df.iloc[start_idx:end_idx]\n            \n            split_data.append({\n                \"id\": row[\"id\"],\n                \"subject_id\": row[\"subject_id\"],\n                \"trial\": trial_num,\n                \"label\": label,\n                \"data\": trial_data\n            })\n        \n        print(f\"\\n  Loaded {len(split_data)} trials\")\n        return split_data\n    \n    return {\n        \"train\": read_split(\"train\"),\n        \"validation\": read_split(\"validation\"),\n        \"test\": read_split(\"test\")\n    }\n\nprint(\"âœ… Data loading function defined\")","metadata":{"_uuid":"4ec19d0c-084c-44be-b851-711e8f307649","_cell_guid":"b72d0caa-cc17-4012-a3d6-d2d7cdfcc598","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.762030Z","iopub.execute_input":"2025-07-24T06:08:40.762254Z","iopub.status.idle":"2025-07-24T06:08:40.780099Z","shell.execute_reply.started":"2025-07-24T06:08:40.762238Z","shell.execute_reply":"2025-07-24T06:08:40.779564Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"âœ… Data loading function defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Load and Preprocess Data","metadata":{"_uuid":"d90f054f-b98c-48e3-8294-82fd0e63e6d8","_cell_guid":"384fe224-d739-4ee2-8401-6bbaff7e08f5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load SSVEP data\nprint(\"\\nğŸŸ¡ STEP 1 â€” Loading data files â€¦\")\nssvep_data = load_ssvep_data()\n\n# Initialize preprocessor and augmenter\nprint(\"\\nğŸŸ¡ STEP 2 â€” Initializing preprocessor and augmenter â€¦\")\npreproc = AdvancedSSVEPPreprocessor(fs=250)\naugmenter = SSVEPAugmentation(fs=250)\n\n# Preprocess train and validation data\nprint(\"\\nğŸŸ¡ STEP 3 â€” Pre-processing train & val â€¦\")\nX_all, y_all = [], []\nfor split in [\"train\", \"validation\"]:\n    print(f\"   Â· Working on '{split}' split\")\n    for tr in ssvep_data[split]:\n        if tr[\"label\"] is None:\n            continue\n        try:\n            X_all.append(preproc.preprocess_trial(tr[\"data\"]))\n            y_all.append(tr[\"label\"])\n        except Exception as e:\n            print(f\"     ! Skipped trial {tr['id']} ({e})\")\n\nX_all = np.asarray(X_all)\ny_all = np.asarray(y_all)\nprint(f\"   âœ”  Got {X_all.shape[0]} clean trials\")\nprint(f\"   âœ”  Data shape: {X_all.shape}\")\nprint(f\"   âœ”  Labels: {np.unique(y_all)}\")","metadata":{"_uuid":"3bd8d016-c9b6-45ae-b3a8-00a1bf041756","_cell_guid":"ffff4f98-c6ab-4920-9029-ce2a96644793","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:08:40.780753Z","iopub.execute_input":"2025-07-24T06:08:40.780960Z","iopub.status.idle":"2025-07-24T06:11:46.478778Z","shell.execute_reply.started":"2025-07-24T06:08:40.780935Z","shell.execute_reply":"2025-07-24T06:11:46.477967Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 1 â€” Loading data files â€¦\nLoading train SSVEP data...\n  Processed 4700/2400 trials\n  Loaded 2400 trials\nLoading validation SSVEP data...\n\n  Loaded 50 trials\nLoading test SSVEP data...\n\n  Loaded 50 trials\n\nğŸŸ¡ STEP 2 â€” Initializing preprocessor and augmenter â€¦\n\nğŸŸ¡ STEP 3 â€” Pre-processing train & val â€¦\n   Â· Working on 'train' split\n   Â· Working on 'validation' split\n   âœ”  Got 2450 clean trials\n   âœ”  Data shape: (2450, 9, 1250)\n   âœ”  Labels: ['Backward' 'Forward' 'Left' 'Right']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Data Augmentation and Preparation","metadata":{"_uuid":"bd8bada7-338d-4319-bc5b-77067de05952","_cell_guid":"257a3bd5-4527-48cd-9851-f002aa53f7f7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Apply extensive data augmentation\nprint(\"\\nğŸŸ¡ STEP 4 â€” Augmenting data â€¦\")\nX_aug = np.vstack([\n    X_all,\n    augmenter.phase_perturbation(X_all),\n    augmenter.amplitude_perturbation(X_all),\n    augmenter.frequency_masking(X_all, preproc),\n    augmenter.random_phase_erasing(X_all)\n])\ny_aug = np.hstack([y_all] * 5)\nX_aug = X_aug[..., np.newaxis]  # Add channel dimension for CNN: (N, 9, 1250, 1)\nprint(f\"   âœ”  Augmented dataset shape: {X_aug.shape}\")\n\n# Label encoding and train-val split\nprint(\"\\nğŸŸ¡ STEP 5 â€” Encoding labels & splitting â€¦\")\nle = LabelEncoder()\ny_enc = le.fit_transform(y_aug)\ny_cat = to_categorical(y_enc)\nn_cls = len(le.classes_)\n\nprint(f\"   âœ”  Number of classes: {n_cls}\")\nprint(f\"   âœ”  Class names: {le.classes_}\")\n\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_aug, y_cat, test_size=0.20,\n    stratify=y_enc, random_state=42\n)\nprint(f\"   âœ”  Train: {X_tr.shape[0]}  |  Val: {X_val.shape[0]}\")\n\n# Compute class weights for imbalanced classes\ncls_w = dict(enumerate(\n    compute_class_weight('balanced',\n                         classes=np.unique(np.argmax(y_tr, 1)),\n                         y=np.argmax(y_tr, 1))\n))\nprint(f\"   âœ”  Class weights: {cls_w}\")","metadata":{"_uuid":"3b6fb6e7-9952-4a5b-abef-bbdf4bad1db9","_cell_guid":"a903a8cc-b6a1-47ce-a11c-f1e8c0f362c9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:11:46.479699Z","iopub.execute_input":"2025-07-24T06:11:46.479933Z","iopub.status.idle":"2025-07-24T06:11:52.219964Z","shell.execute_reply.started":"2025-07-24T06:11:46.479913Z","shell.execute_reply":"2025-07-24T06:11:52.219091Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 4 â€” Augmenting data â€¦\n   âœ”  Augmented dataset shape: (12250, 9, 1250, 1)\n\nğŸŸ¡ STEP 5 â€” Encoding labels & splitting â€¦\n   âœ”  Number of classes: 4\n   âœ”  Class names: ['Backward' 'Forward' 'Left' 'Right']\n   âœ”  Train: 9800  |  Val: 2450\n   âœ”  Class weights: {0: 0.9423076923076923, 1: 1.0346283783783783, 2: 1.0225375626043405, 3: 1.0057471264367817}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Model Building and Training","metadata":{"_uuid":"31297418-601c-4803-a36f-1b118f436a28","_cell_guid":"009b5363-2b13-411b-ba7d-28cef4ec9553","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Build enhanced EEGNet model\nprint(\"\\nğŸŸ¡ STEP 6 â€” Building EEGNet-Attention â€¦\")\nmodel = EEGNet_SSVEP_Enhanced(\n    nb_classes=n_cls,\n    Chans=X_tr.shape[1], Samples=X_tr.shape[2],\n    dropoutRate=0.30, kernLength=64, F1=16, D=2, F2=32,\n    use_attention=True\n)\n\n# Compile with focal loss and SGDR scheduler\nmodel.compile(\n    optimizer=optimizers.Adam(3e-4),\n    loss=focal_loss_ls(gamma=2., alpha=0.75, label_smoothing=0.0),\n    metrics=['accuracy']\n)\n\nprint(\"   âœ”  Model compiled\")\nprint(f\"   âœ”  Model parameters: {model.count_params():,}\")\n\n# Display model architecture\nmodel.summary()","metadata":{"_uuid":"79733557-4873-4e2f-8cc3-80a8742d42d6","_cell_guid":"7b0ed7ad-77b0-4567-baab-1769d3e5b555","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:34:36.500913Z","iopub.execute_input":"2025-07-24T06:34:36.501514Z","iopub.status.idle":"2025-07-24T06:34:36.659350Z","shell.execute_reply.started":"2025-07-24T06:34:36.501490Z","shell.execute_reply":"2025-07-24T06:34:36.658747Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 6 â€” Building EEGNet-Attention â€¦\n   âœ”  Model compiled\n   âœ”  Model parameters: 16,388\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m1\u001b[0m)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\nâ”‚                     â”‚ \u001b[38;5;34m16\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚         \u001b[38;5;34m64\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m16\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ depthwise_conv2d_1  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚        \u001b[38;5;34m288\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚        \u001b[38;5;34m128\u001b[0m â”‚ depthwise_conv2dâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1250\u001b[0m,   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d_2 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ average_pooling2â€¦ â”‚\nâ”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚      \u001b[38;5;34m4,224\u001b[0m â”‚ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚         \u001b[38;5;34m64\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ separable_conv2d_2  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚      \u001b[38;5;34m1,536\u001b[0m â”‚ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚        \u001b[38;5;34m128\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_4        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m312\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d_3 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m32\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m32\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ average_pooling2â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ separable_conv2d_3  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m64\u001b[0m) â”‚      \u001b[38;5;34m2,304\u001b[0m â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”‚ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m64\u001b[0m) â”‚        \u001b[38;5;34m256\u001b[0m â”‚ separable_conv2dâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_5        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m64\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m4,160\u001b[0m â”‚ global_average_pâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚        \u001b[38;5;34m132\u001b[0m â”‚ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ depthwise_conv2d_1  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ depthwise_conv2dâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>,   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d_2 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ average_pooling2â€¦ â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\nâ”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ separable_conv2d_2  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ separable_conv2dâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_4        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d_3 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ average_pooling2â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ separable_conv2d_3  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ separable_conv2dâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ activation_5        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ global_average_pâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> â”‚ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,388\u001b[0m (64.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,388</span> (64.02 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,100\u001b[0m (62.89 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,100</span> (62.89 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Training with Advanced Callbacks","metadata":{"_uuid":"ac7890b5-9563-4d8e-86d5-9e0416f91308","_cell_guid":"577899f7-8ade-4fe4-bf26-e9c83606b976","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train the model with advanced callbacks\nprint(\"\\nğŸŸ¡ STEP 7 â€” Training â€¦ (this may take a while)\")\n\n# Define callbacks\ncallbacks_list = [\n    sgdr_sched,  # Cosine annealing with warm restarts\n    tf.keras.callbacks.EarlyStopping(\n        'val_accuracy', patience=40, restore_best_weights=True,\n        min_delta=0.001, verbose=1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'best_eegnet_attention_ssvep.h5',\n        monitor='val_accuracy', save_best_only=True,\n        mode='max', verbose=1\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss', factor=0.5, patience=20,\n        min_lr=1e-7, verbose=1\n    )\n]\n\n# Train the model\nhistory = model.fit(\n    X_tr, y_tr,\n    validation_data=(X_val, y_val),\n    epochs=200, batch_size=64,\n    class_weight=cls_w,\n    callbacks=callbacks_list,\n    verbose=1\n)\n\nprint(\"   âœ”  Training complete\")","metadata":{"_uuid":"4c5d2712-931e-40cb-9a3e-e3b17edd1218","_cell_guid":"8969977b-f527-4289-9fc2-222b66939fe5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:34:42.429561Z","iopub.execute_input":"2025-07-24T06:34:42.430142Z","iopub.status.idle":"2025-07-24T06:55:00.254012Z","shell.execute_reply.started":"2025-07-24T06:34:42.430120Z","shell.execute_reply":"2025-07-24T06:55:00.253433Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 7 â€” Training â€¦ (this may take a while)\n\nEpoch 001 â€” SGDR LR: 6.09409e-06\nEpoch 1/200\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2428 - loss: 0.6978\nEpoch 1: val_accuracy improved from -inf to 0.26571, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.2428 - loss: 0.6978 - val_accuracy: 0.2657 - val_loss: 0.6929 - learning_rate: 6.0941e-06\n\nEpoch 002 â€” SGDR LR: 5.1307e-06\nEpoch 2/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2481 - loss: 0.6964\nEpoch 2: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.2480 - loss: 0.6964 - val_accuracy: 0.2576 - val_loss: 0.6926 - learning_rate: 5.1307e-06\n\nEpoch 003 â€” SGDR LR: 4.26693e-06\nEpoch 3/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2447 - loss: 0.6953\nEpoch 3: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.2447 - loss: 0.6953 - val_accuracy: 0.2408 - val_loss: 0.6928 - learning_rate: 4.2669e-06\n\nEpoch 004 â€” SGDR LR: 3.50339e-06\nEpoch 4/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2467 - loss: 0.6940\nEpoch 4: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2467 - loss: 0.6940 - val_accuracy: 0.2392 - val_loss: 0.6932 - learning_rate: 3.5034e-06\n\nEpoch 005 â€” SGDR LR: 2.84059e-06\nEpoch 5/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2467 - loss: 0.6940\nEpoch 5: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2467 - loss: 0.6940 - val_accuracy: 0.2392 - val_loss: 0.6931 - learning_rate: 2.8406e-06\n\nEpoch 006 â€” SGDR LR: 2.27899e-06\nEpoch 6/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2535 - loss: 0.6931\nEpoch 6: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2534 - loss: 0.6931 - val_accuracy: 0.2392 - val_loss: 0.6929 - learning_rate: 2.2790e-06\n\nEpoch 007 â€” SGDR LR: 1.81898e-06\nEpoch 7/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2534 - loss: 0.6933\nEpoch 7: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.2534 - loss: 0.6933 - val_accuracy: 0.2396 - val_loss: 0.6927 - learning_rate: 1.8190e-06\n\nEpoch 008 â€” SGDR LR: 1.46086e-06\nEpoch 8/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2475 - loss: 0.6934\nEpoch 8: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.2475 - loss: 0.6934 - val_accuracy: 0.2392 - val_loss: 0.6925 - learning_rate: 1.4609e-06\n\nEpoch 009 â€” SGDR LR: 1.20488e-06\nEpoch 9/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2476 - loss: 0.6927\nEpoch 9: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.2476 - loss: 0.6927 - val_accuracy: 0.2400 - val_loss: 0.6923 - learning_rate: 1.2049e-06\n\nEpoch 010 â€” SGDR LR: 1.05123e-06\nEpoch 10/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2509 - loss: 0.6931\nEpoch 10: val_accuracy did not improve from 0.26571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2509 - loss: 0.6931 - val_accuracy: 0.2392 - val_loss: 0.6922 - learning_rate: 1.0512e-06\n\nEpoch 011 â€” SGDR LR: 0.0003\nEpoch 11/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2534 - loss: 0.6860\nEpoch 11: val_accuracy improved from 0.26571 to 0.28816, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2536 - loss: 0.6859 - val_accuracy: 0.2882 - val_loss: 0.6670 - learning_rate: 3.0000e-04\n\nEpoch 012 â€” SGDR LR: 0.000299987\nEpoch 12/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2853 - loss: 0.6623\nEpoch 12: val_accuracy improved from 0.28816 to 0.30367, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.2853 - loss: 0.6622 - val_accuracy: 0.3037 - val_loss: 0.6452 - learning_rate: 2.9999e-04\n\nEpoch 013 â€” SGDR LR: 0.000299949\nEpoch 13/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3024 - loss: 0.6405\nEpoch 13: val_accuracy did not improve from 0.30367\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.3025 - loss: 0.6405 - val_accuracy: 0.2857 - val_loss: 0.6304 - learning_rate: 2.9995e-04\n\nEpoch 014 â€” SGDR LR: 0.000299885\nEpoch 14/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3460 - loss: 0.6091\nEpoch 14: val_accuracy improved from 0.30367 to 0.37714, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.3463 - loss: 0.6090 - val_accuracy: 0.3771 - val_loss: 0.5671 - learning_rate: 2.9988e-04\n\nEpoch 015 â€” SGDR LR: 0.000299795\nEpoch 15/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4084 - loss: 0.5578\nEpoch 15: val_accuracy improved from 0.37714 to 0.43265, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.4086 - loss: 0.5577 - val_accuracy: 0.4327 - val_loss: 0.5234 - learning_rate: 2.9980e-04\n\nEpoch 016 â€” SGDR LR: 0.00029968\nEpoch 16/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4772 - loss: 0.5124\nEpoch 16: val_accuracy improved from 0.43265 to 0.55878, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.4774 - loss: 0.5123 - val_accuracy: 0.5588 - val_loss: 0.4634 - learning_rate: 2.9968e-04\n\nEpoch 017 â€” SGDR LR: 0.000299539\nEpoch 17/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5313 - loss: 0.4742\nEpoch 17: val_accuracy improved from 0.55878 to 0.58694, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.5315 - loss: 0.4741 - val_accuracy: 0.5869 - val_loss: 0.4460 - learning_rate: 2.9954e-04\n\nEpoch 018 â€” SGDR LR: 0.000299373\nEpoch 18/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5721 - loss: 0.4521\nEpoch 18: val_accuracy improved from 0.58694 to 0.59429, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.5721 - loss: 0.4521 - val_accuracy: 0.5943 - val_loss: 0.4214 - learning_rate: 2.9937e-04\n\nEpoch 019 â€” SGDR LR: 0.000299181\nEpoch 19/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5852 - loss: 0.4303\nEpoch 19: val_accuracy improved from 0.59429 to 0.60408, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.5853 - loss: 0.4303 - val_accuracy: 0.6041 - val_loss: 0.4061 - learning_rate: 2.9918e-04\n\nEpoch 020 â€” SGDR LR: 0.000298964\nEpoch 20/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5915 - loss: 0.4192\nEpoch 20: val_accuracy improved from 0.60408 to 0.61755, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.5916 - loss: 0.4192 - val_accuracy: 0.6176 - val_loss: 0.3938 - learning_rate: 2.9896e-04\n\nEpoch 021 â€” SGDR LR: 0.000298721\nEpoch 21/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5943 - loss: 0.4115\nEpoch 21: val_accuracy did not improve from 0.61755\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.5944 - loss: 0.4114 - val_accuracy: 0.6163 - val_loss: 0.3856 - learning_rate: 2.9872e-04\n\nEpoch 022 â€” SGDR LR: 0.000298453\nEpoch 22/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6030 - loss: 0.4050\nEpoch 22: val_accuracy improved from 0.61755 to 0.62286, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6031 - loss: 0.4050 - val_accuracy: 0.6229 - val_loss: 0.3794 - learning_rate: 2.9845e-04\n\nEpoch 023 â€” SGDR LR: 0.000298159\nEpoch 23/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6132 - loss: 0.3942\nEpoch 23: val_accuracy improved from 0.62286 to 0.62694, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6133 - loss: 0.3942 - val_accuracy: 0.6269 - val_loss: 0.3749 - learning_rate: 2.9816e-04\n\nEpoch 024 â€” SGDR LR: 0.000297841\nEpoch 24/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6149 - loss: 0.3898\nEpoch 24: val_accuracy improved from 0.62694 to 0.62735, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6149 - loss: 0.3897 - val_accuracy: 0.6273 - val_loss: 0.3752 - learning_rate: 2.9784e-04\n\nEpoch 025 â€” SGDR LR: 0.000297497\nEpoch 25/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6200 - loss: 0.3872\nEpoch 25: val_accuracy improved from 0.62735 to 0.63837, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6200 - loss: 0.3872 - val_accuracy: 0.6384 - val_loss: 0.3653 - learning_rate: 2.9750e-04\n\nEpoch 026 â€” SGDR LR: 0.000297127\nEpoch 26/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6291 - loss: 0.3787\nEpoch 26: val_accuracy improved from 0.63837 to 0.64857, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6291 - loss: 0.3787 - val_accuracy: 0.6486 - val_loss: 0.3578 - learning_rate: 2.9713e-04\n\nEpoch 027 â€” SGDR LR: 0.000296733\nEpoch 27/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6374 - loss: 0.3734\nEpoch 27: val_accuracy improved from 0.64857 to 0.65429, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6374 - loss: 0.3733 - val_accuracy: 0.6543 - val_loss: 0.3495 - learning_rate: 2.9673e-04\n\nEpoch 028 â€” SGDR LR: 0.000296314\nEpoch 28/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6377 - loss: 0.3727\nEpoch 28: val_accuracy improved from 0.65429 to 0.65878, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6378 - loss: 0.3727 - val_accuracy: 0.6588 - val_loss: 0.3445 - learning_rate: 2.9631e-04\n\nEpoch 029 â€” SGDR LR: 0.000295869\nEpoch 29/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6407 - loss: 0.3653\nEpoch 29: val_accuracy did not improve from 0.65878\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6408 - loss: 0.3653 - val_accuracy: 0.6584 - val_loss: 0.3434 - learning_rate: 2.9587e-04\n\nEpoch 030 â€” SGDR LR: 0.0002954\nEpoch 30/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6489 - loss: 0.3581\nEpoch 30: val_accuracy improved from 0.65878 to 0.66612, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6489 - loss: 0.3581 - val_accuracy: 0.6661 - val_loss: 0.3383 - learning_rate: 2.9540e-04\n\nEpoch 031 â€” SGDR LR: 0.000294906\nEpoch 31/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6594 - loss: 0.3541\nEpoch 31: val_accuracy did not improve from 0.66612\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6594 - loss: 0.3540 - val_accuracy: 0.6624 - val_loss: 0.3360 - learning_rate: 2.9491e-04\n\nEpoch 032 â€” SGDR LR: 0.000294387\nEpoch 32/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6597 - loss: 0.3511\nEpoch 32: val_accuracy improved from 0.66612 to 0.66857, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6597 - loss: 0.3510 - val_accuracy: 0.6686 - val_loss: 0.3297 - learning_rate: 2.9439e-04\n\nEpoch 033 â€” SGDR LR: 0.000293844\nEpoch 33/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6492 - loss: 0.3545\nEpoch 33: val_accuracy did not improve from 0.66857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6493 - loss: 0.3545 - val_accuracy: 0.6608 - val_loss: 0.3329 - learning_rate: 2.9384e-04\n\nEpoch 034 â€” SGDR LR: 0.000293275\nEpoch 34/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6638 - loss: 0.3454\nEpoch 34: val_accuracy improved from 0.66857 to 0.66898, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6638 - loss: 0.3454 - val_accuracy: 0.6690 - val_loss: 0.3272 - learning_rate: 2.9328e-04\n\nEpoch 035 â€” SGDR LR: 0.000292683\nEpoch 35/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6637 - loss: 0.3398\nEpoch 35: val_accuracy did not improve from 0.66898\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6637 - loss: 0.3398 - val_accuracy: 0.6682 - val_loss: 0.3248 - learning_rate: 2.9268e-04\n\nEpoch 036 â€” SGDR LR: 0.000292066\nEpoch 36/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6786 - loss: 0.3347\nEpoch 36: val_accuracy did not improve from 0.66898\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6785 - loss: 0.3347 - val_accuracy: 0.6665 - val_loss: 0.3228 - learning_rate: 2.9207e-04\n\nEpoch 037 â€” SGDR LR: 0.000291425\nEpoch 37/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6617 - loss: 0.3389\nEpoch 37: val_accuracy improved from 0.66898 to 0.67633, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6618 - loss: 0.3388 - val_accuracy: 0.6763 - val_loss: 0.3196 - learning_rate: 2.9142e-04\n\nEpoch 038 â€” SGDR LR: 0.00029076\nEpoch 38/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6709 - loss: 0.3343\nEpoch 38: val_accuracy did not improve from 0.67633\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6709 - loss: 0.3343 - val_accuracy: 0.6751 - val_loss: 0.3175 - learning_rate: 2.9076e-04\n\nEpoch 039 â€” SGDR LR: 0.00029007\nEpoch 39/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6761 - loss: 0.3282\nEpoch 39: val_accuracy improved from 0.67633 to 0.68245, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6761 - loss: 0.3283 - val_accuracy: 0.6824 - val_loss: 0.3176 - learning_rate: 2.9007e-04\n\nEpoch 040 â€” SGDR LR: 0.000289357\nEpoch 40/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6740 - loss: 0.3250\nEpoch 40: val_accuracy did not improve from 0.68245\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6740 - loss: 0.3250 - val_accuracy: 0.6747 - val_loss: 0.3179 - learning_rate: 2.8936e-04\n\nEpoch 041 â€” SGDR LR: 0.00028862\nEpoch 41/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6775 - loss: 0.3266\nEpoch 41: val_accuracy improved from 0.68245 to 0.68490, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6775 - loss: 0.3266 - val_accuracy: 0.6849 - val_loss: 0.3114 - learning_rate: 2.8862e-04\n\nEpoch 042 â€” SGDR LR: 0.000287859\nEpoch 42/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6820 - loss: 0.3226\nEpoch 42: val_accuracy improved from 0.68490 to 0.68531, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6820 - loss: 0.3226 - val_accuracy: 0.6853 - val_loss: 0.3098 - learning_rate: 2.8786e-04\n\nEpoch 043 â€” SGDR LR: 0.000287075\nEpoch 43/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6805 - loss: 0.3240\nEpoch 43: val_accuracy did not improve from 0.68531\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6806 - loss: 0.3240 - val_accuracy: 0.6845 - val_loss: 0.3084 - learning_rate: 2.8708e-04\n\nEpoch 044 â€” SGDR LR: 0.000286267\nEpoch 44/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6819 - loss: 0.3215\nEpoch 44: val_accuracy improved from 0.68531 to 0.69755, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6820 - loss: 0.3215 - val_accuracy: 0.6976 - val_loss: 0.3057 - learning_rate: 2.8627e-04\n\nEpoch 045 â€” SGDR LR: 0.000285437\nEpoch 45/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6856 - loss: 0.3173\nEpoch 45: val_accuracy did not improve from 0.69755\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6856 - loss: 0.3173 - val_accuracy: 0.6841 - val_loss: 0.3040 - learning_rate: 2.8544e-04\n\nEpoch 046 â€” SGDR LR: 0.000284582\nEpoch 46/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6910 - loss: 0.3150\nEpoch 46: val_accuracy did not improve from 0.69755\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6910 - loss: 0.3150 - val_accuracy: 0.6935 - val_loss: 0.3068 - learning_rate: 2.8458e-04\n\nEpoch 047 â€” SGDR LR: 0.000283705\nEpoch 47/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6919 - loss: 0.3131\nEpoch 47: val_accuracy did not improve from 0.69755\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6919 - loss: 0.3132 - val_accuracy: 0.6894 - val_loss: 0.3014 - learning_rate: 2.8371e-04\n\nEpoch 048 â€” SGDR LR: 0.000282806\nEpoch 48/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6914 - loss: 0.3128\nEpoch 48: val_accuracy improved from 0.69755 to 0.69837, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6914 - loss: 0.3128 - val_accuracy: 0.6984 - val_loss: 0.3033 - learning_rate: 2.8281e-04\n\nEpoch 049 â€” SGDR LR: 0.000281883\nEpoch 49/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6934 - loss: 0.3114\nEpoch 49: val_accuracy improved from 0.69837 to 0.70694, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6934 - loss: 0.3113 - val_accuracy: 0.7069 - val_loss: 0.2929 - learning_rate: 2.8188e-04\n\nEpoch 050 â€” SGDR LR: 0.000280938\nEpoch 50/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6959 - loss: 0.3055\nEpoch 50: val_accuracy did not improve from 0.70694\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6958 - loss: 0.3055 - val_accuracy: 0.6951 - val_loss: 0.2948 - learning_rate: 2.8094e-04\n\nEpoch 051 â€” SGDR LR: 0.000279971\nEpoch 51/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6899 - loss: 0.3108\nEpoch 51: val_accuracy improved from 0.70694 to 0.70776, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6900 - loss: 0.3108 - val_accuracy: 0.7078 - val_loss: 0.2930 - learning_rate: 2.7997e-04\n\nEpoch 052 â€” SGDR LR: 0.000278981\nEpoch 52/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6985 - loss: 0.3060\nEpoch 52: val_accuracy did not improve from 0.70776\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6985 - loss: 0.3060 - val_accuracy: 0.7065 - val_loss: 0.2896 - learning_rate: 2.7898e-04\n\nEpoch 053 â€” SGDR LR: 0.00027797\nEpoch 53/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7014 - loss: 0.3039\nEpoch 53: val_accuracy did not improve from 0.70776\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7014 - loss: 0.3039 - val_accuracy: 0.7033 - val_loss: 0.2886 - learning_rate: 2.7797e-04\n\nEpoch 054 â€” SGDR LR: 0.000276936\nEpoch 54/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6933 - loss: 0.3074\nEpoch 54: val_accuracy improved from 0.70776 to 0.71184, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6933 - loss: 0.3074 - val_accuracy: 0.7118 - val_loss: 0.2856 - learning_rate: 2.7694e-04\n\nEpoch 055 â€” SGDR LR: 0.000275881\nEpoch 55/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6953 - loss: 0.3016\nEpoch 55: val_accuracy did not improve from 0.71184\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6953 - loss: 0.3016 - val_accuracy: 0.7098 - val_loss: 0.2888 - learning_rate: 2.7588e-04\n\nEpoch 056 â€” SGDR LR: 0.000274805\nEpoch 56/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6994 - loss: 0.3001\nEpoch 56: val_accuracy improved from 0.71184 to 0.71388, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - accuracy: 0.6994 - loss: 0.3001 - val_accuracy: 0.7139 - val_loss: 0.2871 - learning_rate: 2.7480e-04\n\nEpoch 057 â€” SGDR LR: 0.000273707\nEpoch 57/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6995 - loss: 0.3029\nEpoch 57: val_accuracy did not improve from 0.71388\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.6996 - loss: 0.3029 - val_accuracy: 0.7069 - val_loss: 0.2859 - learning_rate: 2.7371e-04\n\nEpoch 058 â€” SGDR LR: 0.000272588\nEpoch 58/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7114 - loss: 0.2968\nEpoch 58: val_accuracy did not improve from 0.71388\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7114 - loss: 0.2968 - val_accuracy: 0.7139 - val_loss: 0.2812 - learning_rate: 2.7259e-04\n\nEpoch 059 â€” SGDR LR: 0.000271448\nEpoch 59/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7071 - loss: 0.2953\nEpoch 59: val_accuracy improved from 0.71388 to 0.72122, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7071 - loss: 0.2953 - val_accuracy: 0.7212 - val_loss: 0.2829 - learning_rate: 2.7145e-04\n\nEpoch 060 â€” SGDR LR: 0.000270287\nEpoch 60/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7095 - loss: 0.2931\nEpoch 60: val_accuracy did not improve from 0.72122\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7095 - loss: 0.2931 - val_accuracy: 0.7184 - val_loss: 0.2800 - learning_rate: 2.7029e-04\n\nEpoch 061 â€” SGDR LR: 0.000269106\nEpoch 61/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7031 - loss: 0.2947\nEpoch 61: val_accuracy did not improve from 0.72122\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7031 - loss: 0.2947 - val_accuracy: 0.7114 - val_loss: 0.2844 - learning_rate: 2.6911e-04\n\nEpoch 062 â€” SGDR LR: 0.000267905\nEpoch 62/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7071 - loss: 0.2950\nEpoch 62: val_accuracy did not improve from 0.72122\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7071 - loss: 0.2949 - val_accuracy: 0.7188 - val_loss: 0.2781 - learning_rate: 2.6790e-04\n\nEpoch 063 â€” SGDR LR: 0.000266683\nEpoch 63/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7125 - loss: 0.2920\nEpoch 63: val_accuracy improved from 0.72122 to 0.72857, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7125 - loss: 0.2919 - val_accuracy: 0.7286 - val_loss: 0.2741 - learning_rate: 2.6668e-04\n\nEpoch 064 â€” SGDR LR: 0.000265442\nEpoch 64/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7110 - loss: 0.2922\nEpoch 64: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7110 - loss: 0.2922 - val_accuracy: 0.7159 - val_loss: 0.2772 - learning_rate: 2.6544e-04\n\nEpoch 065 â€” SGDR LR: 0.000264181\nEpoch 65/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7105 - loss: 0.2916\nEpoch 65: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7105 - loss: 0.2916 - val_accuracy: 0.7237 - val_loss: 0.2757 - learning_rate: 2.6418e-04\n\nEpoch 066 â€” SGDR LR: 0.0002629\nEpoch 66/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7208 - loss: 0.2838\nEpoch 66: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7207 - loss: 0.2839 - val_accuracy: 0.7163 - val_loss: 0.2791 - learning_rate: 2.6290e-04\n\nEpoch 067 â€” SGDR LR: 0.0002616\nEpoch 67/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7130 - loss: 0.2873\nEpoch 67: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7130 - loss: 0.2873 - val_accuracy: 0.7184 - val_loss: 0.2746 - learning_rate: 2.6160e-04\n\nEpoch 068 â€” SGDR LR: 0.000260281\nEpoch 68/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7246 - loss: 0.2841\nEpoch 68: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7246 - loss: 0.2841 - val_accuracy: 0.7237 - val_loss: 0.2722 - learning_rate: 2.6028e-04\n\nEpoch 069 â€” SGDR LR: 0.000258943\nEpoch 69/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7062 - loss: 0.2876\nEpoch 69: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7063 - loss: 0.2875 - val_accuracy: 0.7286 - val_loss: 0.2735 - learning_rate: 2.5894e-04\n\nEpoch 070 â€” SGDR LR: 0.000257587\nEpoch 70/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7156 - loss: 0.2854\nEpoch 70: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7156 - loss: 0.2854 - val_accuracy: 0.7229 - val_loss: 0.2691 - learning_rate: 2.5759e-04\n\nEpoch 071 â€” SGDR LR: 0.000256212\nEpoch 71/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7267 - loss: 0.2791\nEpoch 71: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7266 - loss: 0.2792 - val_accuracy: 0.7216 - val_loss: 0.2705 - learning_rate: 2.5621e-04\n\nEpoch 072 â€” SGDR LR: 0.00025482\nEpoch 72/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7149 - loss: 0.2827\nEpoch 72: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7150 - loss: 0.2827 - val_accuracy: 0.7286 - val_loss: 0.2669 - learning_rate: 2.5482e-04\n\nEpoch 073 â€” SGDR LR: 0.000253409\nEpoch 73/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7205 - loss: 0.2830\nEpoch 73: val_accuracy did not improve from 0.72857\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7205 - loss: 0.2830 - val_accuracy: 0.7241 - val_loss: 0.2738 - learning_rate: 2.5341e-04\n\nEpoch 074 â€” SGDR LR: 0.000251981\nEpoch 74/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7245 - loss: 0.2733\nEpoch 74: val_accuracy improved from 0.72857 to 0.72939, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7245 - loss: 0.2733 - val_accuracy: 0.7294 - val_loss: 0.2675 - learning_rate: 2.5198e-04\n\nEpoch 075 â€” SGDR LR: 0.000250535\nEpoch 75/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7186 - loss: 0.2799\nEpoch 75: val_accuracy improved from 0.72939 to 0.73184, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7187 - loss: 0.2798 - val_accuracy: 0.7318 - val_loss: 0.2632 - learning_rate: 2.5054e-04\n\nEpoch 076 â€” SGDR LR: 0.000249072\nEpoch 76/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7205 - loss: 0.2766\nEpoch 76: val_accuracy did not improve from 0.73184\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7205 - loss: 0.2766 - val_accuracy: 0.7314 - val_loss: 0.2673 - learning_rate: 2.4907e-04\n\nEpoch 077 â€” SGDR LR: 0.000247592\nEpoch 77/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7199 - loss: 0.2771\nEpoch 77: val_accuracy improved from 0.73184 to 0.74204, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7200 - loss: 0.2771 - val_accuracy: 0.7420 - val_loss: 0.2623 - learning_rate: 2.4759e-04\n\nEpoch 078 â€” SGDR LR: 0.000246096\nEpoch 78/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7208 - loss: 0.2771\nEpoch 78: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7208 - loss: 0.2771 - val_accuracy: 0.7371 - val_loss: 0.2646 - learning_rate: 2.4610e-04\n\nEpoch 079 â€” SGDR LR: 0.000244583\nEpoch 79/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7263 - loss: 0.2731\nEpoch 79: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7263 - loss: 0.2731 - val_accuracy: 0.7314 - val_loss: 0.2616 - learning_rate: 2.4458e-04\n\nEpoch 080 â€” SGDR LR: 0.000243055\nEpoch 80/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7274 - loss: 0.2791\nEpoch 80: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7275 - loss: 0.2790 - val_accuracy: 0.7380 - val_loss: 0.2620 - learning_rate: 2.4305e-04\n\nEpoch 081 â€” SGDR LR: 0.00024151\nEpoch 81/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7258 - loss: 0.2695\nEpoch 81: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7259 - loss: 0.2695 - val_accuracy: 0.7367 - val_loss: 0.2599 - learning_rate: 2.4151e-04\n\nEpoch 082 â€” SGDR LR: 0.00023995\nEpoch 82/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7204 - loss: 0.2770\nEpoch 82: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7204 - loss: 0.2769 - val_accuracy: 0.7404 - val_loss: 0.2575 - learning_rate: 2.3995e-04\n\nEpoch 083 â€” SGDR LR: 0.000238374\nEpoch 83/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7346 - loss: 0.2714\nEpoch 83: val_accuracy did not improve from 0.74204\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7345 - loss: 0.2714 - val_accuracy: 0.7359 - val_loss: 0.2589 - learning_rate: 2.3837e-04\n\nEpoch 084 â€” SGDR LR: 0.000236783\nEpoch 84/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7219 - loss: 0.2725\nEpoch 84: val_accuracy improved from 0.74204 to 0.74327, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7219 - loss: 0.2725 - val_accuracy: 0.7433 - val_loss: 0.2578 - learning_rate: 2.3678e-04\n\nEpoch 085 â€” SGDR LR: 0.000235178\nEpoch 85/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7282 - loss: 0.2678\nEpoch 85: val_accuracy did not improve from 0.74327\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7282 - loss: 0.2679 - val_accuracy: 0.7392 - val_loss: 0.2557 - learning_rate: 2.3518e-04\n\nEpoch 086 â€” SGDR LR: 0.000233558\nEpoch 86/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7346 - loss: 0.2657\nEpoch 86: val_accuracy did not improve from 0.74327\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7346 - loss: 0.2657 - val_accuracy: 0.7331 - val_loss: 0.2615 - learning_rate: 2.3356e-04\n\nEpoch 087 â€” SGDR LR: 0.000231924\nEpoch 87/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7255 - loss: 0.2673\nEpoch 87: val_accuracy did not improve from 0.74327\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7255 - loss: 0.2672 - val_accuracy: 0.7400 - val_loss: 0.2565 - learning_rate: 2.3192e-04\n\nEpoch 088 â€” SGDR LR: 0.000230275\nEpoch 88/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7315 - loss: 0.2663\nEpoch 88: val_accuracy did not improve from 0.74327\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7315 - loss: 0.2663 - val_accuracy: 0.7433 - val_loss: 0.2572 - learning_rate: 2.3028e-04\n\nEpoch 089 â€” SGDR LR: 0.000228614\nEpoch 89/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7341 - loss: 0.2605\nEpoch 89: val_accuracy did not improve from 0.74327\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7341 - loss: 0.2605 - val_accuracy: 0.7392 - val_loss: 0.2542 - learning_rate: 2.2861e-04\n\nEpoch 090 â€” SGDR LR: 0.000226938\nEpoch 90/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7357 - loss: 0.2648\nEpoch 90: val_accuracy improved from 0.74327 to 0.74490, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7357 - loss: 0.2648 - val_accuracy: 0.7449 - val_loss: 0.2533 - learning_rate: 2.2694e-04\n\nEpoch 091 â€” SGDR LR: 0.00022525\nEpoch 91/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7334 - loss: 0.2704\nEpoch 91: val_accuracy did not improve from 0.74490\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7335 - loss: 0.2704 - val_accuracy: 0.7416 - val_loss: 0.2535 - learning_rate: 2.2525e-04\n\nEpoch 092 â€” SGDR LR: 0.000223549\nEpoch 92/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7306 - loss: 0.2638\nEpoch 92: val_accuracy did not improve from 0.74490\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7307 - loss: 0.2638 - val_accuracy: 0.7363 - val_loss: 0.2540 - learning_rate: 2.2355e-04\n\nEpoch 093 â€” SGDR LR: 0.000221835\nEpoch 93/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7310 - loss: 0.2651\nEpoch 93: val_accuracy did not improve from 0.74490\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7311 - loss: 0.2651 - val_accuracy: 0.7441 - val_loss: 0.2522 - learning_rate: 2.2184e-04\n\nEpoch 094 â€” SGDR LR: 0.000220109\nEpoch 94/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7369 - loss: 0.2594\nEpoch 94: val_accuracy did not improve from 0.74490\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7369 - loss: 0.2594 - val_accuracy: 0.7441 - val_loss: 0.2493 - learning_rate: 2.2011e-04\n\nEpoch 095 â€” SGDR LR: 0.000218372\nEpoch 95/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7405 - loss: 0.2602\nEpoch 95: val_accuracy did not improve from 0.74490\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7404 - loss: 0.2602 - val_accuracy: 0.7400 - val_loss: 0.2533 - learning_rate: 2.1837e-04\n\nEpoch 096 â€” SGDR LR: 0.000216622\nEpoch 96/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7461 - loss: 0.2587\nEpoch 96: val_accuracy improved from 0.74490 to 0.74531, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7460 - loss: 0.2587 - val_accuracy: 0.7453 - val_loss: 0.2517 - learning_rate: 2.1662e-04\n\nEpoch 097 â€” SGDR LR: 0.000214861\nEpoch 97/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7346 - loss: 0.2618\nEpoch 97: val_accuracy improved from 0.74531 to 0.75265, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7347 - loss: 0.2618 - val_accuracy: 0.7527 - val_loss: 0.2515 - learning_rate: 2.1486e-04\n\nEpoch 098 â€” SGDR LR: 0.00021309\nEpoch 98/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7359 - loss: 0.2598\nEpoch 98: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7359 - loss: 0.2598 - val_accuracy: 0.7420 - val_loss: 0.2489 - learning_rate: 2.1309e-04\n\nEpoch 099 â€” SGDR LR: 0.000211307\nEpoch 99/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7402 - loss: 0.2581\nEpoch 99: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7402 - loss: 0.2581 - val_accuracy: 0.7437 - val_loss: 0.2481 - learning_rate: 2.1131e-04\n\nEpoch 100 â€” SGDR LR: 0.000209514\nEpoch 100/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7386 - loss: 0.2609\nEpoch 100: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7386 - loss: 0.2609 - val_accuracy: 0.7469 - val_loss: 0.2468 - learning_rate: 2.0951e-04\n\nEpoch 101 â€” SGDR LR: 0.000207711\nEpoch 101/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7380 - loss: 0.2563\nEpoch 101: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7380 - loss: 0.2563 - val_accuracy: 0.7494 - val_loss: 0.2460 - learning_rate: 2.0771e-04\n\nEpoch 102 â€” SGDR LR: 0.000205898\nEpoch 102/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7397 - loss: 0.2540\nEpoch 102: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7397 - loss: 0.2540 - val_accuracy: 0.7482 - val_loss: 0.2432 - learning_rate: 2.0590e-04\n\nEpoch 103 â€” SGDR LR: 0.000204076\nEpoch 103/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7476 - loss: 0.2521\nEpoch 103: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7475 - loss: 0.2522 - val_accuracy: 0.7506 - val_loss: 0.2487 - learning_rate: 2.0408e-04\n\nEpoch 104 â€” SGDR LR: 0.000202245\nEpoch 104/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7408 - loss: 0.2605\nEpoch 104: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7408 - loss: 0.2605 - val_accuracy: 0.7445 - val_loss: 0.2504 - learning_rate: 2.0224e-04\n\nEpoch 105 â€” SGDR LR: 0.000200404\nEpoch 105/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7346 - loss: 0.2578\nEpoch 105: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7346 - loss: 0.2578 - val_accuracy: 0.7424 - val_loss: 0.2519 - learning_rate: 2.0040e-04\n\nEpoch 106 â€” SGDR LR: 0.000198555\nEpoch 106/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7401 - loss: 0.2526\nEpoch 106: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7401 - loss: 0.2526 - val_accuracy: 0.7522 - val_loss: 0.2432 - learning_rate: 1.9856e-04\n\nEpoch 107 â€” SGDR LR: 0.000196698\nEpoch 107/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7411 - loss: 0.2547\nEpoch 107: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7411 - loss: 0.2547 - val_accuracy: 0.7502 - val_loss: 0.2441 - learning_rate: 1.9670e-04\n\nEpoch 108 â€” SGDR LR: 0.000194833\nEpoch 108/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7445 - loss: 0.2485\nEpoch 108: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7445 - loss: 0.2485 - val_accuracy: 0.7494 - val_loss: 0.2422 - learning_rate: 1.9483e-04\n\nEpoch 109 â€” SGDR LR: 0.00019296\nEpoch 109/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7513 - loss: 0.2448\nEpoch 109: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7513 - loss: 0.2449 - val_accuracy: 0.7445 - val_loss: 0.2499 - learning_rate: 1.9296e-04\n\nEpoch 110 â€” SGDR LR: 0.00019108\nEpoch 110/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7465 - loss: 0.2482\nEpoch 110: val_accuracy did not improve from 0.75265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7465 - loss: 0.2482 - val_accuracy: 0.7514 - val_loss: 0.2422 - learning_rate: 1.9108e-04\n\nEpoch 111 â€” SGDR LR: 0.000189193\nEpoch 111/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7366 - loss: 0.2508\nEpoch 111: val_accuracy improved from 0.75265 to 0.75388, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7367 - loss: 0.2508 - val_accuracy: 0.7539 - val_loss: 0.2486 - learning_rate: 1.8919e-04\n\nEpoch 112 â€” SGDR LR: 0.0001873\nEpoch 112/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7423 - loss: 0.2524\nEpoch 112: val_accuracy did not improve from 0.75388\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7423 - loss: 0.2523 - val_accuracy: 0.7514 - val_loss: 0.2468 - learning_rate: 1.8730e-04\n\nEpoch 113 â€” SGDR LR: 0.0001854\nEpoch 113/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7448 - loss: 0.2494\nEpoch 113: val_accuracy did not improve from 0.75388\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7448 - loss: 0.2495 - val_accuracy: 0.7510 - val_loss: 0.2425 - learning_rate: 1.8540e-04\n\nEpoch 114 â€” SGDR LR: 0.000183494\nEpoch 114/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7453 - loss: 0.2528\nEpoch 114: val_accuracy did not improve from 0.75388\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7453 - loss: 0.2528 - val_accuracy: 0.7514 - val_loss: 0.2374 - learning_rate: 1.8349e-04\n\nEpoch 115 â€” SGDR LR: 0.000181583\nEpoch 115/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7471 - loss: 0.2477\nEpoch 115: val_accuracy improved from 0.75388 to 0.75469, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7471 - loss: 0.2477 - val_accuracy: 0.7547 - val_loss: 0.2405 - learning_rate: 1.8158e-04\n\nEpoch 116 â€” SGDR LR: 0.000179666\nEpoch 116/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7559 - loss: 0.2468\nEpoch 116: val_accuracy did not improve from 0.75469\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7558 - loss: 0.2468 - val_accuracy: 0.7498 - val_loss: 0.2417 - learning_rate: 1.7967e-04\n\nEpoch 117 â€” SGDR LR: 0.000177744\nEpoch 117/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7462 - loss: 0.2507\nEpoch 117: val_accuracy improved from 0.75469 to 0.75959, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7462 - loss: 0.2507 - val_accuracy: 0.7596 - val_loss: 0.2399 - learning_rate: 1.7774e-04\n\nEpoch 118 â€” SGDR LR: 0.000175818\nEpoch 118/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7391 - loss: 0.2460\nEpoch 118: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7392 - loss: 0.2459 - val_accuracy: 0.7531 - val_loss: 0.2420 - learning_rate: 1.7582e-04\n\nEpoch 119 â€” SGDR LR: 0.000173887\nEpoch 119/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7499 - loss: 0.2465\nEpoch 119: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7499 - loss: 0.2464 - val_accuracy: 0.7539 - val_loss: 0.2356 - learning_rate: 1.7389e-04\n\nEpoch 120 â€” SGDR LR: 0.000171952\nEpoch 120/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7505 - loss: 0.2429\nEpoch 120: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7505 - loss: 0.2430 - val_accuracy: 0.7498 - val_loss: 0.2372 - learning_rate: 1.7195e-04\n\nEpoch 121 â€” SGDR LR: 0.000170014\nEpoch 121/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7488 - loss: 0.2457\nEpoch 121: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7488 - loss: 0.2457 - val_accuracy: 0.7522 - val_loss: 0.2332 - learning_rate: 1.7001e-04\n\nEpoch 122 â€” SGDR LR: 0.000168072\nEpoch 122/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7520 - loss: 0.2416\nEpoch 122: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7520 - loss: 0.2417 - val_accuracy: 0.7588 - val_loss: 0.2345 - learning_rate: 1.6807e-04\n\nEpoch 123 â€” SGDR LR: 0.000166127\nEpoch 123/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7419 - loss: 0.2511\nEpoch 123: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7419 - loss: 0.2510 - val_accuracy: 0.7527 - val_loss: 0.2324 - learning_rate: 1.6613e-04\n\nEpoch 124 â€” SGDR LR: 0.000164179\nEpoch 124/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7506 - loss: 0.2447\nEpoch 124: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7506 - loss: 0.2447 - val_accuracy: 0.7576 - val_loss: 0.2353 - learning_rate: 1.6418e-04\n\nEpoch 125 â€” SGDR LR: 0.00016223\nEpoch 125/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7478 - loss: 0.2434\nEpoch 125: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7478 - loss: 0.2434 - val_accuracy: 0.7535 - val_loss: 0.2365 - learning_rate: 1.6223e-04\n\nEpoch 126 â€” SGDR LR: 0.000160278\nEpoch 126/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7538 - loss: 0.2446\nEpoch 126: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7538 - loss: 0.2446 - val_accuracy: 0.7510 - val_loss: 0.2362 - learning_rate: 1.6028e-04\n\nEpoch 127 â€” SGDR LR: 0.000158324\nEpoch 127/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7462 - loss: 0.2414\nEpoch 127: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7463 - loss: 0.2414 - val_accuracy: 0.7531 - val_loss: 0.2339 - learning_rate: 1.5832e-04\n\nEpoch 128 â€” SGDR LR: 0.000156369\nEpoch 128/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7461 - loss: 0.2439\nEpoch 128: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7461 - loss: 0.2439 - val_accuracy: 0.7588 - val_loss: 0.2321 - learning_rate: 1.5637e-04\n\nEpoch 129 â€” SGDR LR: 0.000154413\nEpoch 129/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7445 - loss: 0.2498\nEpoch 129: val_accuracy did not improve from 0.75959\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7445 - loss: 0.2497 - val_accuracy: 0.7559 - val_loss: 0.2354 - learning_rate: 1.5441e-04\n\nEpoch 130 â€” SGDR LR: 0.000152457\nEpoch 130/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7545 - loss: 0.2398\nEpoch 130: val_accuracy improved from 0.75959 to 0.76204, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7545 - loss: 0.2398 - val_accuracy: 0.7620 - val_loss: 0.2344 - learning_rate: 1.5246e-04\n\nEpoch 131 â€” SGDR LR: 0.0001505\nEpoch 131/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7525 - loss: 0.2395\nEpoch 131: val_accuracy improved from 0.76204 to 0.76286, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7525 - loss: 0.2395 - val_accuracy: 0.7629 - val_loss: 0.2362 - learning_rate: 1.5050e-04\n\nEpoch 132 â€” SGDR LR: 0.000148543\nEpoch 132/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7485 - loss: 0.2463\nEpoch 132: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7485 - loss: 0.2462 - val_accuracy: 0.7612 - val_loss: 0.2336 - learning_rate: 1.4854e-04\n\nEpoch 133 â€” SGDR LR: 0.000146587\nEpoch 133/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7578 - loss: 0.2369\nEpoch 133: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7578 - loss: 0.2370 - val_accuracy: 0.7563 - val_loss: 0.2337 - learning_rate: 1.4659e-04\n\nEpoch 134 â€” SGDR LR: 0.000144631\nEpoch 134/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7533 - loss: 0.2406\nEpoch 134: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7534 - loss: 0.2406 - val_accuracy: 0.7629 - val_loss: 0.2284 - learning_rate: 1.4463e-04\n\nEpoch 135 â€” SGDR LR: 0.000142676\nEpoch 135/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7497 - loss: 0.2455\nEpoch 135: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7497 - loss: 0.2454 - val_accuracy: 0.7616 - val_loss: 0.2283 - learning_rate: 1.4268e-04\n\nEpoch 136 â€” SGDR LR: 0.000140722\nEpoch 136/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7529 - loss: 0.2424\nEpoch 136: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7529 - loss: 0.2424 - val_accuracy: 0.7608 - val_loss: 0.2309 - learning_rate: 1.4072e-04\n\nEpoch 137 â€” SGDR LR: 0.00013877\nEpoch 137/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7527 - loss: 0.2434\nEpoch 137: val_accuracy did not improve from 0.76286\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7527 - loss: 0.2433 - val_accuracy: 0.7616 - val_loss: 0.2266 - learning_rate: 1.3877e-04\n\nEpoch 138 â€” SGDR LR: 0.000136821\nEpoch 138/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7514 - loss: 0.2395\nEpoch 138: val_accuracy improved from 0.76286 to 0.76408, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7514 - loss: 0.2395 - val_accuracy: 0.7641 - val_loss: 0.2286 - learning_rate: 1.3682e-04\n\nEpoch 139 â€” SGDR LR: 0.000134873\nEpoch 139/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7627 - loss: 0.2366\nEpoch 139: val_accuracy did not improve from 0.76408\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7627 - loss: 0.2366 - val_accuracy: 0.7620 - val_loss: 0.2335 - learning_rate: 1.3487e-04\n\nEpoch 140 â€” SGDR LR: 0.000132928\nEpoch 140/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7543 - loss: 0.2380\nEpoch 140: val_accuracy did not improve from 0.76408\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7544 - loss: 0.2380 - val_accuracy: 0.7588 - val_loss: 0.2305 - learning_rate: 1.3293e-04\n\nEpoch 141 â€” SGDR LR: 0.000130986\nEpoch 141/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7479 - loss: 0.2387\nEpoch 141: val_accuracy improved from 0.76408 to 0.76571, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7480 - loss: 0.2387 - val_accuracy: 0.7657 - val_loss: 0.2288 - learning_rate: 1.3099e-04\n\nEpoch 142 â€” SGDR LR: 0.000129048\nEpoch 142/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7482 - loss: 0.2423\nEpoch 142: val_accuracy did not improve from 0.76571\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7483 - loss: 0.2422 - val_accuracy: 0.7551 - val_loss: 0.2362 - learning_rate: 1.2905e-04\n\nEpoch 143 â€” SGDR LR: 0.000127113\nEpoch 143/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7512 - loss: 0.2382\nEpoch 143: val_accuracy improved from 0.76571 to 0.76612, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7512 - loss: 0.2382 - val_accuracy: 0.7661 - val_loss: 0.2309 - learning_rate: 1.2711e-04\n\nEpoch 144 â€” SGDR LR: 0.000125182\nEpoch 144/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7558 - loss: 0.2384\nEpoch 144: val_accuracy did not improve from 0.76612\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7558 - loss: 0.2384 - val_accuracy: 0.7576 - val_loss: 0.2297 - learning_rate: 1.2518e-04\n\nEpoch 145 â€” SGDR LR: 0.000123256\nEpoch 145/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7560 - loss: 0.2328\nEpoch 145: val_accuracy did not improve from 0.76612\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7560 - loss: 0.2329 - val_accuracy: 0.7661 - val_loss: 0.2293 - learning_rate: 1.2326e-04\n\nEpoch 146 â€” SGDR LR: 0.000121334\nEpoch 146/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7535 - loss: 0.2376\nEpoch 146: val_accuracy improved from 0.76612 to 0.76776, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7535 - loss: 0.2376 - val_accuracy: 0.7678 - val_loss: 0.2252 - learning_rate: 1.2133e-04\n\nEpoch 147 â€” SGDR LR: 0.000119417\nEpoch 147/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7621 - loss: 0.2336\nEpoch 147: val_accuracy improved from 0.76776 to 0.76816, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7621 - loss: 0.2336 - val_accuracy: 0.7682 - val_loss: 0.2296 - learning_rate: 1.1942e-04\n\nEpoch 148 â€” SGDR LR: 0.000117506\nEpoch 148/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7556 - loss: 0.2387\nEpoch 148: val_accuracy improved from 0.76816 to 0.76939, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7556 - loss: 0.2386 - val_accuracy: 0.7694 - val_loss: 0.2232 - learning_rate: 1.1751e-04\n\nEpoch 149 â€” SGDR LR: 0.0001156\nEpoch 149/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7557 - loss: 0.2351\nEpoch 149: val_accuracy did not improve from 0.76939\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7557 - loss: 0.2351 - val_accuracy: 0.7633 - val_loss: 0.2313 - learning_rate: 1.1560e-04\n\nEpoch 150 â€” SGDR LR: 0.0001137\nEpoch 150/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7519 - loss: 0.2359\nEpoch 150: val_accuracy did not improve from 0.76939\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7520 - loss: 0.2359 - val_accuracy: 0.7686 - val_loss: 0.2299 - learning_rate: 1.1370e-04\n\nEpoch 151 â€” SGDR LR: 0.000111807\nEpoch 151/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7487 - loss: 0.2387\nEpoch 151: val_accuracy did not improve from 0.76939\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7488 - loss: 0.2387 - val_accuracy: 0.7690 - val_loss: 0.2243 - learning_rate: 1.1181e-04\n\nEpoch 152 â€” SGDR LR: 0.00010992\nEpoch 152/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7648 - loss: 0.2331\nEpoch 152: val_accuracy improved from 0.76939 to 0.77061, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7648 - loss: 0.2331 - val_accuracy: 0.7706 - val_loss: 0.2241 - learning_rate: 1.0992e-04\n\nEpoch 153 â€” SGDR LR: 0.00010804\nEpoch 153/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7532 - loss: 0.2326\nEpoch 153: val_accuracy did not improve from 0.77061\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7532 - loss: 0.2326 - val_accuracy: 0.7669 - val_loss: 0.2237 - learning_rate: 1.0804e-04\n\nEpoch 154 â€” SGDR LR: 0.000106167\nEpoch 154/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7576 - loss: 0.2328\nEpoch 154: val_accuracy did not improve from 0.77061\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7575 - loss: 0.2328 - val_accuracy: 0.7686 - val_loss: 0.2267 - learning_rate: 1.0617e-04\n\nEpoch 155 â€” SGDR LR: 0.000104302\nEpoch 155/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7607 - loss: 0.2331\nEpoch 155: val_accuracy did not improve from 0.77061\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7606 - loss: 0.2331 - val_accuracy: 0.7600 - val_loss: 0.2276 - learning_rate: 1.0430e-04\n\nEpoch 156 â€” SGDR LR: 0.000102445\nEpoch 156/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7663 - loss: 0.2312\nEpoch 156: val_accuracy did not improve from 0.77061\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7663 - loss: 0.2312 - val_accuracy: 0.7661 - val_loss: 0.2296 - learning_rate: 1.0244e-04\n\nEpoch 157 â€” SGDR LR: 0.000100596\nEpoch 157/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7639 - loss: 0.2307\nEpoch 157: val_accuracy improved from 0.77061 to 0.77143, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7639 - loss: 0.2307 - val_accuracy: 0.7714 - val_loss: 0.2234 - learning_rate: 1.0060e-04\n\nEpoch 158 â€” SGDR LR: 9.87555e-05\nEpoch 158/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7651 - loss: 0.2311\nEpoch 158: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7651 - loss: 0.2311 - val_accuracy: 0.7653 - val_loss: 0.2268 - learning_rate: 9.8756e-05\n\nEpoch 159 â€” SGDR LR: 9.6924e-05\nEpoch 159/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7653 - loss: 0.2276\nEpoch 159: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7653 - loss: 0.2277 - val_accuracy: 0.7665 - val_loss: 0.2251 - learning_rate: 9.6924e-05\n\nEpoch 160 â€” SGDR LR: 9.51017e-05\nEpoch 160/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7484 - loss: 0.2330\nEpoch 160: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7485 - loss: 0.2329 - val_accuracy: 0.7633 - val_loss: 0.2236 - learning_rate: 9.5102e-05\n\nEpoch 161 â€” SGDR LR: 9.32888e-05\nEpoch 161/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7591 - loss: 0.2317\nEpoch 161: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7591 - loss: 0.2317 - val_accuracy: 0.7714 - val_loss: 0.2229 - learning_rate: 9.3289e-05\n\nEpoch 162 â€” SGDR LR: 9.14858e-05\nEpoch 162/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7597 - loss: 0.2311\nEpoch 162: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7597 - loss: 0.2311 - val_accuracy: 0.7698 - val_loss: 0.2262 - learning_rate: 9.1486e-05\n\nEpoch 163 â€” SGDR LR: 8.96929e-05\nEpoch 163/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7567 - loss: 0.2321\nEpoch 163: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7568 - loss: 0.2321 - val_accuracy: 0.7710 - val_loss: 0.2209 - learning_rate: 8.9693e-05\n\nEpoch 164 â€” SGDR LR: 8.79104e-05\nEpoch 164/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7592 - loss: 0.2260\nEpoch 164: val_accuracy did not improve from 0.77143\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7593 - loss: 0.2260 - val_accuracy: 0.7669 - val_loss: 0.2213 - learning_rate: 8.7910e-05\n\nEpoch 165 â€” SGDR LR: 8.61386e-05\nEpoch 165/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7617 - loss: 0.2272\nEpoch 165: val_accuracy improved from 0.77143 to 0.77265, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7617 - loss: 0.2272 - val_accuracy: 0.7727 - val_loss: 0.2198 - learning_rate: 8.6139e-05\n\nEpoch 166 â€” SGDR LR: 8.43778e-05\nEpoch 166/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7623 - loss: 0.2293\nEpoch 166: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7623 - loss: 0.2293 - val_accuracy: 0.7710 - val_loss: 0.2207 - learning_rate: 8.4378e-05\n\nEpoch 167 â€” SGDR LR: 8.26284e-05\nEpoch 167/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7590 - loss: 0.2286\nEpoch 167: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7591 - loss: 0.2287 - val_accuracy: 0.7702 - val_loss: 0.2251 - learning_rate: 8.2628e-05\n\nEpoch 168 â€” SGDR LR: 8.08906e-05\nEpoch 168/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7590 - loss: 0.2284\nEpoch 168: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7590 - loss: 0.2284 - val_accuracy: 0.7718 - val_loss: 0.2254 - learning_rate: 8.0891e-05\n\nEpoch 169 â€” SGDR LR: 7.91648e-05\nEpoch 169/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7685 - loss: 0.2210\nEpoch 169: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7685 - loss: 0.2210 - val_accuracy: 0.7665 - val_loss: 0.2239 - learning_rate: 7.9165e-05\n\nEpoch 170 â€” SGDR LR: 7.74511e-05\nEpoch 170/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7656 - loss: 0.2287\nEpoch 170: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7656 - loss: 0.2287 - val_accuracy: 0.7710 - val_loss: 0.2201 - learning_rate: 7.7451e-05\n\nEpoch 171 â€” SGDR LR: 7.575e-05\nEpoch 171/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7610 - loss: 0.2307\nEpoch 171: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7610 - loss: 0.2307 - val_accuracy: 0.7714 - val_loss: 0.2200 - learning_rate: 7.5750e-05\n\nEpoch 172 â€” SGDR LR: 7.40617e-05\nEpoch 172/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7616 - loss: 0.2258\nEpoch 172: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7616 - loss: 0.2258 - val_accuracy: 0.7682 - val_loss: 0.2217 - learning_rate: 7.4062e-05\n\nEpoch 173 â€” SGDR LR: 7.23865e-05\nEpoch 173/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7563 - loss: 0.2306\nEpoch 173: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7563 - loss: 0.2306 - val_accuracy: 0.7669 - val_loss: 0.2195 - learning_rate: 7.2386e-05\n\nEpoch 174 â€” SGDR LR: 7.07246e-05\nEpoch 174/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7688 - loss: 0.2209\nEpoch 174: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7688 - loss: 0.2209 - val_accuracy: 0.7669 - val_loss: 0.2233 - learning_rate: 7.0725e-05\n\nEpoch 175 â€” SGDR LR: 6.90765e-05\nEpoch 175/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7582 - loss: 0.2272\nEpoch 175: val_accuracy did not improve from 0.77265\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7582 - loss: 0.2272 - val_accuracy: 0.7690 - val_loss: 0.2223 - learning_rate: 6.9076e-05\n\nEpoch 176 â€” SGDR LR: 6.74423e-05\nEpoch 176/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7525 - loss: 0.2294\nEpoch 176: val_accuracy improved from 0.77265 to 0.77388, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7526 - loss: 0.2294 - val_accuracy: 0.7739 - val_loss: 0.2195 - learning_rate: 6.7442e-05\n\nEpoch 177 â€” SGDR LR: 6.58223e-05\nEpoch 177/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7671 - loss: 0.2249\nEpoch 177: val_accuracy improved from 0.77388 to 0.77510, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7671 - loss: 0.2249 - val_accuracy: 0.7751 - val_loss: 0.2175 - learning_rate: 6.5822e-05\n\nEpoch 178 â€” SGDR LR: 6.42168e-05\nEpoch 178/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7732 - loss: 0.2214\nEpoch 178: val_accuracy did not improve from 0.77510\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7732 - loss: 0.2215 - val_accuracy: 0.7731 - val_loss: 0.2207 - learning_rate: 6.4217e-05\n\nEpoch 179 â€” SGDR LR: 6.26261e-05\nEpoch 179/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7641 - loss: 0.2244\nEpoch 179: val_accuracy did not improve from 0.77510\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7641 - loss: 0.2245 - val_accuracy: 0.7735 - val_loss: 0.2245 - learning_rate: 6.2626e-05\n\nEpoch 180 â€” SGDR LR: 6.10505e-05\nEpoch 180/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7658 - loss: 0.2282\nEpoch 180: val_accuracy did not improve from 0.77510\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7659 - loss: 0.2282 - val_accuracy: 0.7735 - val_loss: 0.2242 - learning_rate: 6.1050e-05\n\nEpoch 181 â€” SGDR LR: 5.94902e-05\nEpoch 181/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7706 - loss: 0.2220\nEpoch 181: val_accuracy did not improve from 0.77510\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7705 - loss: 0.2220 - val_accuracy: 0.7743 - val_loss: 0.2178 - learning_rate: 5.9490e-05\n\nEpoch 182 â€” SGDR LR: 5.79455e-05\nEpoch 182/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7699 - loss: 0.2181\nEpoch 182: val_accuracy did not improve from 0.77510\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7699 - loss: 0.2181 - val_accuracy: 0.7731 - val_loss: 0.2217 - learning_rate: 5.7945e-05\n\nEpoch 183 â€” SGDR LR: 5.64166e-05\nEpoch 183/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7655 - loss: 0.2225\nEpoch 183: val_accuracy improved from 0.77510 to 0.77714, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7655 - loss: 0.2226 - val_accuracy: 0.7771 - val_loss: 0.2186 - learning_rate: 5.6417e-05\n\nEpoch 184 â€” SGDR LR: 5.49039e-05\nEpoch 184/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7715 - loss: 0.2233\nEpoch 184: val_accuracy did not improve from 0.77714\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7715 - loss: 0.2233 - val_accuracy: 0.7743 - val_loss: 0.2182 - learning_rate: 5.4904e-05\n\nEpoch 185 â€” SGDR LR: 5.34075e-05\nEpoch 185/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7740 - loss: 0.2240\nEpoch 185: val_accuracy improved from 0.77714 to 0.77796, saving model to best_eegnet_attention_ssvep.h5\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7739 - loss: 0.2241 - val_accuracy: 0.7780 - val_loss: 0.2214 - learning_rate: 5.3408e-05\n\nEpoch 186 â€” SGDR LR: 5.19278e-05\nEpoch 186/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7679 - loss: 0.2215\nEpoch 186: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7679 - loss: 0.2216 - val_accuracy: 0.7776 - val_loss: 0.2188 - learning_rate: 5.1928e-05\n\nEpoch 187 â€” SGDR LR: 5.0465e-05\nEpoch 187/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7663 - loss: 0.2275\nEpoch 187: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7663 - loss: 0.2274 - val_accuracy: 0.7714 - val_loss: 0.2186 - learning_rate: 5.0465e-05\n\nEpoch 188 â€” SGDR LR: 4.90193e-05\nEpoch 188/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7680 - loss: 0.2224\nEpoch 188: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7680 - loss: 0.2225 - val_accuracy: 0.7722 - val_loss: 0.2184 - learning_rate: 4.9019e-05\n\nEpoch 189 â€” SGDR LR: 4.7591e-05\nEpoch 189/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7739 - loss: 0.2208\nEpoch 189: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7738 - loss: 0.2208 - val_accuracy: 0.7731 - val_loss: 0.2164 - learning_rate: 4.7591e-05\n\nEpoch 190 â€” SGDR LR: 4.61803e-05\nEpoch 190/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7630 - loss: 0.2244\nEpoch 190: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7630 - loss: 0.2244 - val_accuracy: 0.7767 - val_loss: 0.2177 - learning_rate: 4.6180e-05\n\nEpoch 191 â€” SGDR LR: 4.47875e-05\nEpoch 191/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7681 - loss: 0.2231\nEpoch 191: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7680 - loss: 0.2231 - val_accuracy: 0.7722 - val_loss: 0.2158 - learning_rate: 4.4788e-05\n\nEpoch 192 â€” SGDR LR: 4.34129e-05\nEpoch 192/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7719 - loss: 0.2192\nEpoch 192: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7719 - loss: 0.2192 - val_accuracy: 0.7743 - val_loss: 0.2163 - learning_rate: 4.3413e-05\n\nEpoch 193 â€” SGDR LR: 4.20565e-05\nEpoch 193/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7667 - loss: 0.2246\nEpoch 193: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7667 - loss: 0.2246 - val_accuracy: 0.7751 - val_loss: 0.2158 - learning_rate: 4.2057e-05\n\nEpoch 194 â€” SGDR LR: 4.07188e-05\nEpoch 194/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7750 - loss: 0.2210\nEpoch 194: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - accuracy: 0.7750 - loss: 0.2209 - val_accuracy: 0.7722 - val_loss: 0.2187 - learning_rate: 4.0719e-05\n\nEpoch 195 â€” SGDR LR: 3.93998e-05\nEpoch 195/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7651 - loss: 0.2254\nEpoch 195: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7651 - loss: 0.2254 - val_accuracy: 0.7739 - val_loss: 0.2165 - learning_rate: 3.9400e-05\n\nEpoch 196 â€” SGDR LR: 3.80999e-05\nEpoch 196/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7667 - loss: 0.2243\nEpoch 196: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7667 - loss: 0.2243 - val_accuracy: 0.7731 - val_loss: 0.2167 - learning_rate: 3.8100e-05\n\nEpoch 197 â€” SGDR LR: 3.68193e-05\nEpoch 197/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7696 - loss: 0.2220\nEpoch 197: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7695 - loss: 0.2221 - val_accuracy: 0.7722 - val_loss: 0.2164 - learning_rate: 3.6819e-05\n\nEpoch 198 â€” SGDR LR: 3.55581e-05\nEpoch 198/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7740 - loss: 0.2232\nEpoch 198: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7739 - loss: 0.2232 - val_accuracy: 0.7727 - val_loss: 0.2214 - learning_rate: 3.5558e-05\n\nEpoch 199 â€” SGDR LR: 3.43167e-05\nEpoch 199/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7686 - loss: 0.2227\nEpoch 199: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7686 - loss: 0.2227 - val_accuracy: 0.7747 - val_loss: 0.2169 - learning_rate: 3.4317e-05\n\nEpoch 200 â€” SGDR LR: 3.30951e-05\nEpoch 200/200\n\u001b[1m153/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7688 - loss: 0.2235\nEpoch 200: val_accuracy did not improve from 0.77796\n\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.7688 - loss: 0.2235 - val_accuracy: 0.7731 - val_loss: 0.2157 - learning_rate: 3.3095e-05\nRestoring model weights from the end of the best epoch: 183.\n   âœ”  Training complete\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Test Time Augmentation (TTA) Setup","metadata":{"_uuid":"78df1f24-f6d5-49cd-aac2-fdc65905228a","_cell_guid":"45ad2512-1013-495b-90c1-cef0c3fcc3dd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Setup Test Time Augmentation\nprint(\"\\nğŸŸ¡ STEP 8 â€” Preparing TTA helper â€¦\")\n\n# Define TTA transformations\ntta_tfms = [\n    lambda x: x,  # Original\n    lambda x, aug=augmenter: aug.phase_perturbation(x[np.newaxis])[0],\n    lambda x, aug=augmenter: aug.amplitude_perturbation(x[np.newaxis])[0],\n    lambda x, aug=augmenter, pp=preproc: aug.frequency_masking(x[np.newaxis], pp)[0]\n]\n\n# Temperature calibration for better confidence scores\nT = 2.0\ndef softmax_T(logits, T=T, eps=1e-12):\n    \"\"\"Temperature-scaled softmax\"\"\"\n    l = np.log(np.clip(logits, eps, 1.0)) / T\n    e = np.exp(l - l.max())\n    return e / e.sum()\n\n# TTA prediction function\ndef tta_predict(sig):\n    \"\"\"Predict using Test Time Augmentation\"\"\"\n    probs = []\n    for f in tta_tfms:\n        aug = f(sig)[..., np.newaxis][np.newaxis]  # Shape: (1, 9, 1250, 1)\n        probs.append(model.predict(aug, verbose=0)[0])\n    \n    # Average probabilities and apply temperature scaling\n    p_mean = softmax_T(np.mean(probs, 0))\n    idx = int(p_mean.argmax()) % n_cls  # Ensure valid class index\n    return idx, p_mean.max()\n\nprint(\"   âœ”  TTA setup complete\")","metadata":{"_uuid":"0b9993b2-6ca6-4ac1-b824-6e3542c97bf0","_cell_guid":"67c5ee13-8510-43a2-9766-9fd861ff6e46","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:55:05.473148Z","iopub.execute_input":"2025-07-24T06:55:05.473674Z","iopub.status.idle":"2025-07-24T06:55:05.480947Z","shell.execute_reply.started":"2025-07-24T06:55:05.473631Z","shell.execute_reply":"2025-07-24T06:55:05.480339Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 8 â€” Preparing TTA helper â€¦\n   âœ”  TTA setup complete\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Process Test Data and Generate Predictions","metadata":{"_uuid":"e6aaa269-eb54-4914-8f52-dcd138a6bfcb","_cell_guid":"ede8a974-cade-43a7-9b4b-aec1392eff93","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Process test data\nprint(\"\\nğŸŸ¡ STEP 9 â€” Pre-processing test set â€¦\")\nX_test, ids = [], []\nfor tr in ssvep_data['test']:\n    ids.append(tr['id'])\n    try:\n        X_test.append(preproc.preprocess_trial(tr['data']))\n    except Exception as e:\n        print(f\"     ! Test trial {tr['id']} failed ({e}) â€“ inserting zeros\")\n        X_test.append(np.zeros((9, 1250)))\n\nX_test = np.asarray(X_test)\nprint(f\"   âœ”  Test trials ready: {X_test.shape[0]}\")\n\n# Run TTA inference\nprint(\"\\nğŸŸ¡ STEP 10 â€” Running TTA inference â€¦\")\nlabels, confid = [], []\nfor i, sig in enumerate(X_test):\n    if i % 10 == 0:\n        print(f\"   Processing {i}/{len(X_test)} trials\", end='\\r')\n    cls_idx, conf = tta_predict(sig)\n    labels.append(le.classes_[cls_idx])\n    confid.append(conf)\n\nprint(f\"\\n   âœ”  Inference complete\")\nprint(f\"   âœ”  Prediction distribution:\")\nunique_labels, counts = np.unique(labels, return_counts=True)\nfor label, count in zip(unique_labels, counts):\n    print(f\"     {label}: {count}\")","metadata":{"_uuid":"056f6fe9-cf15-42eb-b16d-f434b6945c91","_cell_guid":"4d647e67-7782-43c4-bf30-8c07ccf1a648","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T06:55:07.019847Z","iopub.execute_input":"2025-07-24T06:55:07.020115Z","iopub.status.idle":"2025-07-24T06:55:22.341164Z","shell.execute_reply.started":"2025-07-24T06:55:07.020094Z","shell.execute_reply":"2025-07-24T06:55:22.340336Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 9 â€” Pre-processing test set â€¦\n   âœ”  Test trials ready: 50\n\nğŸŸ¡ STEP 10 â€” Running TTA inference â€¦\n   Processing 40/50 trials\n   âœ”  Inference complete\n   âœ”  Prediction distribution:\n     Backward: 10\n     Forward: 14\n     Left: 19\n     Right: 7\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Evaluation and Validation Results","metadata":{"_uuid":"b3131ec4-d6cd-4e61-8482-cc05d52d649b","_cell_guid":"d40445a2-21f5-427b-8f2c-36b2d7db1fda","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Evaluate on validation set first\nprint(\"\\nğŸŸ¡ STEP 11 â€” Validation set evaluation â€¦\")\n\n# Get validation predictions using TTA\nval_predictions = []\nval_confidences = []\n\nfor i, trial in enumerate(X_val):\n    # Remove the extra dimension and predict\n    sig = trial[:, :, 0]  # Remove channel dimension\n    cls_idx, conf = tta_predict(sig)\n    val_predictions.append(cls_idx)\n    val_confidences.append(conf)\n\nval_predictions = np.array(val_predictions)\nval_true = np.argmax(y_val, axis=1)\n\n# Calculate validation accuracy\nval_acc = accuracy_score(val_true, val_predictions)\nprint(f\"   âœ”  Validation Accuracy (TTA): {val_acc:.4f}\")\n\n# Classification report\nprint(\"\\n   Classification Report:\")\nprint(classification_report(val_true, val_predictions, \n                          target_names=le.classes_, digits=4))\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\ncm = confusion_matrix(val_true, val_predictions)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=le.classes_, yticklabels=le.classes_)\nplt.title('Confusion Matrix - Validation Set (TTA)')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"_uuid":"7a637f08-accd-4140-82d0-9974fda64979","_cell_guid":"89924218-7ba6-4b4b-a1fb-44ba2be78d29","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-24T06:55:22.342270Z","iopub.execute_input":"2025-07-24T06:55:22.342517Z","iopub.status.idle":"2025-07-24T07:06:57.295395Z","shell.execute_reply.started":"2025-07-24T06:55:22.342498Z","shell.execute_reply":"2025-07-24T07:06:57.294649Z"}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 11 â€” Validation set evaluation â€¦\n   âœ”  Validation Accuracy (TTA): 0.7747\n\n   Classification Report:\n              precision    recall  f1-score   support\n\n    Backward     0.7757    0.7769    0.7763       650\n     Forward     0.8156    0.7399    0.7759       592\n        Left     0.7731    0.8648    0.8164       599\n       Right     0.7382    0.7176    0.7277       609\n\n    accuracy                         0.7747      2450\n   macro avg     0.7757    0.7748    0.7741      2450\nweighted avg     0.7754    0.7747    0.7739      2450\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## Training History Visualization","metadata":{"_uuid":"f504fec8-208a-45c2-9780-d53245c0d3bc","_cell_guid":"c43dd555-c8ec-44fb-b471-6b2c8241f631","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Plot training history\nprint(\"\\nğŸŸ¡ STEP 12 â€” Visualizing training history â€¦\")\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Accuracy plot\nax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\nax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\nax1.set_title('Model Accuracy')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Accuracy')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Loss plot\nax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\nax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\nax2.set_title('Model Loss')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Loss')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"   âœ”  Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\nprint(f\"   âœ”  Final training accuracy: {history.history['accuracy'][-1]:.4f}\")","metadata":{"_uuid":"566648ee-e4dc-47e8-bddb-dba7cf3f0425","_cell_guid":"b5acd083-6ed0-4d23-abc1-0806e5e3dada","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T07:06:57.296638Z","iopub.execute_input":"2025-07-24T07:06:57.296900Z","iopub.status.idle":"2025-07-24T07:06:57.687699Z","shell.execute_reply.started":"2025-07-24T07:06:57.296881Z","shell.execute_reply":"2025-07-24T07:06:57.686931Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 12 â€” Visualizing training history â€¦\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"   âœ”  Best validation accuracy: 0.7780\n   âœ”  Final training accuracy: 0.7684\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Save Results and Models","metadata":{"_uuid":"a505bb52-1d96-4ab8-b436-fa545a94cab1","_cell_guid":"72600279-12cf-4419-a9ff-bd669c27a575","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Save final outputs\nprint(\"\\nğŸŸ¡ STEP 13 â€” Saving outputs â€¦\")\n\n# Create submission dataframe\nsubmission_df = pd.DataFrame({\n    'id': ids, \n    'label': labels, \n    'confidence': confid\n}).sort_values('id')\n\n# Save submission file\nsubmission_df.to_csv('eegnet_tta_submission.csv', index=False)\nprint(\"   âœ”  CSV saved â†’ eegnet_tta_submission.csv\")\n\n# Save the trained model\nmodel.save('final_eegnet_attention_ssvep.h5')\nprint(\"   âœ”  Model saved â†’ final_eegnet_attention_ssvep.h5\")\n\n# Save preprocessor and label encoder\nwith open('ssvep_preprocessor.pkl', 'wb') as f:\n    pickle.dump(preproc, f)\nprint(\"   âœ”  Preprocessor saved â†’ ssvep_preprocessor.pkl\")\n\nwith open('ssvep_label_encoder.pkl', 'wb') as f:\n    pickle.dump(le, f)\nprint(\"   âœ”  Label encoder saved â†’ ssvep_label_encoder.pkl\")\n\n# Display final submission statistics\nprint(f\"\\n   ğŸ“Š Final submission statistics:\")\nprint(f\"      Total test samples: {len(submission_df)}\")\nprint(f\"      Average confidence: {submission_df['confidence'].mean():.4f}\")\nprint(f\"      Min confidence: {submission_df['confidence'].min():.4f}\")\nprint(f\"      Max confidence: {submission_df['confidence'].max():.4f}\")\n\nprint(\"\\nâœ… PIPELINE COMPLETED SUCCESSFULLY!\")","metadata":{"_uuid":"7ec87d40-edae-40d8-83c4-727c6db53bab","_cell_guid":"cb72e617-e926-4962-8613-51f2737b29ca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-07-24T07:06:57.688509Z","iopub.execute_input":"2025-07-24T07:06:57.688733Z","iopub.status.idle":"2025-07-24T07:06:57.786672Z","shell.execute_reply.started":"2025-07-24T07:06:57.688716Z","shell.execute_reply":"2025-07-24T07:06:57.785949Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nğŸŸ¡ STEP 13 â€” Saving outputs â€¦\n   âœ”  CSV saved â†’ eegnet_tta_submission.csv\n   âœ”  Model saved â†’ final_eegnet_attention_ssvep.h5\n   âœ”  Preprocessor saved â†’ ssvep_preprocessor.pkl\n   âœ”  Label encoder saved â†’ ssvep_label_encoder.pkl\n\n   ğŸ“Š Final submission statistics:\n      Total test samples: 50\n      Average confidence: 0.5374\n      Min confidence: 0.3133\n      Max confidence: 0.9234\n\nâœ… PIPELINE COMPLETED SUCCESSFULLY!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Summary","metadata":{"_uuid":"4bacfbfb-886f-4819-af6f-cf625d6dd9f3","_cell_guid":"6540fcc2-e979-459e-b935-769b205ba683","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"ğŸ¯ ENHANCED SSVEP CLASSIFICATION PIPELINE SUMMARY\")\nprint(\"=\"*60)\n\nprint(f\"\"\"\nğŸ“ˆ MODEL PERFORMANCE:\n   â€¢ Validation Accuracy (TTA): {val_acc:.4f}\n   â€¢ Model Parameters: {model.count_params():,}\n   â€¢ Training Epochs: {len(history.history['accuracy'])}\n   â€¢ Best Val Accuracy: {max(history.history['val_accuracy']):.4f}\n\nğŸ”§ KEY INNOVATIONS IMPLEMENTED:\n   â€¢ Advanced preprocessing with spatial filtering\n   â€¢ Multi-head attention mechanism in EEGNet\n   â€¢ SGDR (Cosine annealing with warm restarts)\n   â€¢ Focal loss with class weighting\n   â€¢ Test Time Augmentation (4 transformations)\n   â€¢ Temperature calibration for confidence scores\n   â€¢ Physiologically-aware data augmentation (5x data)\n\nğŸ“Š AUGMENTATION TECHNIQUES:\n   â€¢ Phase perturbation (temporal shifts)\n   â€¢ Amplitude scaling (0.8-1.2x)\n   â€¢ Frequency masking (random notch filtering)\n   â€¢ Random phase erasing (FFT domain)\n\nğŸ›ï¸ ADVANCED FEATURES:\n   â€¢ Robust artifact rejection\n   â€¢ Bipolar derivation (OZ-PZ)\n   â€¢ Multi-frequency filter banks\n   â€¢ SSVEP-specific preprocessing pipeline\n\n\n\"\"\")","metadata":{"_uuid":"f1e0b67e-0e83-49cd-89c5-b6a2760a0a63","_cell_guid":"20432996-9f47-4f88-a64b-4d3b97e599eb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-24T07:08:55.044372Z","iopub.execute_input":"2025-07-24T07:08:55.044668Z","iopub.status.idle":"2025-07-24T07:08:55.050149Z","shell.execute_reply.started":"2025-07-24T07:08:55.044628Z","shell.execute_reply":"2025-07-24T07:08:55.049505Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸ¯ ENHANCED SSVEP CLASSIFICATION PIPELINE SUMMARY\n============================================================\n\nğŸ“ˆ MODEL PERFORMANCE:\n   â€¢ Validation Accuracy (TTA): 0.7747\n   â€¢ Model Parameters: 16,388\n   â€¢ Training Epochs: 200\n   â€¢ Best Val Accuracy: 0.7780\n\nğŸ”§ KEY INNOVATIONS IMPLEMENTED:\n   â€¢ Advanced preprocessing with spatial filtering\n   â€¢ Multi-head attention mechanism in EEGNet\n   â€¢ SGDR (Cosine annealing with warm restarts)\n   â€¢ Focal loss with class weighting\n   â€¢ Test Time Augmentation (4 transformations)\n   â€¢ Temperature calibration for confidence scores\n   â€¢ Physiologically-aware data augmentation (5x data)\n\nğŸ“Š AUGMENTATION TECHNIQUES:\n   â€¢ Phase perturbation (temporal shifts)\n   â€¢ Amplitude scaling (0.8-1.2x)\n   â€¢ Frequency masking (random notch filtering)\n   â€¢ Random phase erasing (FFT domain)\n\nğŸ›ï¸ ADVANCED FEATURES:\n   â€¢ Robust artifact rejection\n   â€¢ Bipolar derivation (OZ-PZ)\n   â€¢ Multi-frequency filter banks\n   â€¢ SSVEP-specific preprocessing pipeline\n\n\n\n","output_type":"stream"}],"execution_count":22}]}